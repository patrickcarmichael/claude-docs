---
title: "Cohere Documentation"
description: "Formatted documentation for Cohere"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Announcing Embed Multimodal v4

> Release of Embed Multimodal v4, a performant search model, with Matryoshka embeddings and a 128k context length.

Weâ€™re thrilled to announce the release of [Embed 4](https://docs.cohere.com/docs/cohere-embed), the most recent entrant into the Embed family of enterprise-focusedÂ [large language models](https://docs.cohere.com/docs/the-cohere-platform#large-language-models-llms)Â (LLMs).

Embed v4 is Cohereâ€™s most performant search model to date, and supports the following new features:

1. Matryoshka Embeddings in the following dimensions: '\[256, 512, 1024, 1536]'
2. Unified Embeddings produced from mixed modality input (i.e. a single payload of image(s) and text(s))
3. Context length of 128k

Embed v4 achieves state of the art in the following areas:

1. Text-to-text retrieval
2. Text-to-image retrieval
3. Text-to-mixed modality retrieval (from e.g. PDFs)

Embed v4 is available today on the [Cohere Platform](https://docs.cohere.com/docs/the-cohere-platform), [AWS Sagemaker](https://docs.cohere.com/docs/amazon-sagemaker-setup-guide#embeddings), and [Azure AI Foundry](https://docs.cohere.com/docs/cohere-on-microsoft-azure#embeddings). For more information, check out our dedicated blog post [here](https://cohere.com/blog/embed-4).


---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
