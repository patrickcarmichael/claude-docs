**Navigation:** [â† Previous](./13-updates-a-fine-tuned-model.md) | [Index](./index.md) | [Next â†’](./15-multi-step-tool-use-with-cohere.md)

---

# Step 4: Conversation with Memory using AI Messages and Human Messages \[#sec\_step4]

```python PYTHON
a2_mem_ai_hum = agent_executor.invoke({
   "input": q2,
   "chat_history": [HumanMessage(content=q1),
                    AIMessage(content=a1['output'])] # we add here the human query and the generation of the model at turn 1
})
```

```txt title="Output"
[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
I will copy and paste the code from the previous conversation into this one, and then use it to plot the revenue numbers.
{'tool_name': 'python_interpreter', 'parameters': {'code': "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('modified_revenue_table.csv')\n\n# Plot the revenue numbers\nplt.plot(data['revenue'])\n\nplt.savefig('revenue_plot.png')"}}
[0m[36;1m[1;3m[0m[32;1m[1;3mRelevant Documents: 0
Cited Documents: 0
Answer: Here's a plot of the revenue numbers:
<img alt="Revenue plot" revenue_plot.png""="" src=""/>
Grounded answer: Here's a plot of the revenue numbers:
<co: 0="">! [Revenue plot]("revenue_plot.png")</co:>[0m

[1m> Finished chain.[0m
```

It works! Let's go on with the conversation.

```python PYTHON
q3 = "set the min of y axis to zero and the max to 1000"
a3_mem_ai_hum = agent_executor.invoke({
   "input": q3,
   "chat_history": [HumanMessage(content=q1),
                    AIMessage(content=a1['output']),
                    HumanMessage(content=q2), # we now add info from turn 2
                    AIMessage(content=a2_mem_ai_hum['output'])]
})
```

```txt title="Output"
[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
I will copy and paste the previous code and make the changes requested by the user. Then I will execute the code to plot the graph with the changes applied.
{'tool_name': 'python_interpreter', 'parameters': {'code': 'import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file into a DataFrame\ndf = pd.read_csv("modified_revenue_table.csv")\n\n# Plot revenue against time\nplt.plot(df["time"], df["revenue"], marker="o")\n\n# Set minimum and maximum values for y-axis\nplt.ylim(0, 1000)\n\nplt.savefig("revenue_plot.png")'}}
[0m[36;1m[1;3m[0m[32;1m[1;3mRelevant Documents: 0
Cited Documents: 0
Answer: Here's the plot with the requested changes:
<img alt="Revenue plot" revenue_plot.png""="" src=""/>
Grounded answer: Here's the plot with the requested changes:
<co: 0="">! [Revenue plot]("revenue_plot.png")</co:>[0m

[1m> Finished chain.[0m
```

The model does what we asked, but it decides to introduce the marker="o" in the plotting function. While in this case the modification of the code does not affect the quality of the output, this is still an undesidered behaviour, since the model is introducing a modification that was not required.

To address this problem, we can further enrich the chat history by adding information from the reasoning chain.

# Step 5: Conversation with Memory using AI Messages, Human Messages and the Reasoning Chain \[#sec\_step5]

Reasoning chains can be very long, especially in the cases that contain errors and the agent needs several attempts to get to the final output. Hence, by concatenating all the reasoning chains, we might have two issues: (i) noisy information; (ii) we would quickly hit max input length.

To avoid this issue, we need a way to extract the relevant info from the previous turns. Below, we propose a simple approach to info extraction. We format the extracted info in such a way to enhance human interpretability. We call the objects passed in the chat history *augmented memory objects*.

```python PYTHON
# function to create augmented memory objects
def create_augmented_mem_objs(output_previous_turn: dict) -> str:
    """Function to convert the output of a ReAct agent to a compact and interpretable representation"""
    all_steps_info = []
    # loop though the steps of the previous turns
    for i, step in enumerate(output_previous_turn['intermediate_steps']):
        # remove failed attempts
        if "error" not in step[1].lower():
            # collect the relevant info
            step_info = {'tool': step[0].tool,
                         'tool_input': step[0].tool_input}
            all_steps_info.append(step_info)
    # format the memory object in an interpretable way
    augmented_mem_obj = "This is the sequence of tools you used in the previous turn:\n"
    for i, item in enumerate(all_steps_info):
        augmented_mem_obj = augmented_mem_obj + f"\nSTART TOOL {i} NAME:\n{item['tool']}\nEND TOOL {i} NAME" \
                                                f"\n\nSTART INPUT {i} NAME:\n{item['tool_input']}\nEND INPUT {i} NAME\n"
    # add the final output generated by the agent
    augmented_mem_obj = augmented_mem_obj + f"\n\nThis is the output you produced in the previous turn:\nSTART OUTPUT\n{output_previous_turn['output']}\nEND OUTPUT"

    return augmented_mem_obj
```

```python PYTHON
augmented_mem_obj_a1 = create_augmented_mem_objs(a1)
augmented_mem_obj_a2 = create_augmented_mem_objs(a2_mem_ai_hum)
```

Below, an example of the augmented memory object generated by the model. You can see that the agent now has full visibility on what it did in the previous step.

```python PYTHON
print(augmented_mem_obj_a2)
```

```txt title="Output"
This is the sequence of tools you used in the previous turn:

START TOOL 0 NAME:
python_interpreter
END TOOL 0 NAME

START INPUT 0 NAME:
{'code': "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('modified_revenue_table.csv')\n\n# Plot the revenue numbers\nplt.plot(data['revenue'])\n\nplt.savefig('revenue_plot.png')"}
END INPUT 0 NAME


This is the output you produced in the previous turn:
START OUTPUT
Here's a plot of the revenue numbers:
! [Revenue plot]("revenue_plot.png")
END OUTPUT
```

```python PYTHON
a3_mem_ai_hum_amo = agent_executor.invoke({
    "input": q3,
    "chat_history": [SystemMessage(content=augmented_mem_obj_a1),
                     SystemMessage(content=augmented_mem_obj_a2)]
})

```

```txt title="Output"
[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
I will copy and paste the previous code, and modify the y axis limits as requested.
{'tool_name': 'python_interpreter', 'parameters': {'code': "import pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_csv('modified_revenue_table.csv')\n\n# Plot the revenue numbers\nplt.plot(data['revenue'])\n\n# Set y axis limits\nplt.ylim(0, 1000)\n\nplt.savefig('revenue_plot.png')"}}
[0m[36;1m[1;3m[0m[32;1m[1;3mRelevant Documents: 0
Cited Documents: 0
Answer: Here's the plot with the requested y axis limits:

<img alt="Revenue plot" revenue_plot.png""="" src=""/>
Grounded answer: Here's the plot with the requested y axis limits:

<co: 0="">! [Revenue plot]("revenue_plot.png")</co:>[0m

[1m> Finished chain.[0m
```

We can see that, now, the plot only includes the modification we asked for, and nothing else. This is possible because we are now providing the Agent with the code it previously generated, and the Agent re-uses that code, making only the necessary modifications. This is fundamentally different from what we observed before, when the Agent had to re-create from scratch the code.

In sum, by providing the Agent with the information about its previous Reasoning Chain, we make it more robust and able to generate consistent outputs.

In a future post, we will explore how to handle really long historical context using vector databases.


# Agentic Multi-Stage RAG with Cohere Tools API

> This page describes how to build a powerful, multi-stage agent with the Cohere platform.

<AuthorsContainer
  authors={[
    {
      name: "Jason Jung",
      imageSrc: "https://fern-image-hosting.s3.amazonaws.com/cohere/0803e3d-Jason_Jung.jpg",
    },
  ]}
/>

<CookbookHeader href="https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/agents/agentic-RAG/agentic_multi_stage_rag_native.ipynb" />

## Motivation

Retrieval augmented generation (RAG) has been a go-to use case that enterprises have been adopting with large language models (LLMs). Even though it works well in general, there are edge cases where this can fail. Most commonly, when the retrieved document mentions the query but actually refers to another document, the model will fail to generate the correct answer.

We propose an agentic RAG system that leverages tool use to continue to retrieve documents if correct ones were not retrieved at first try. This is ideal for use cases where accuracy is a top priority and latency is not. For example, lawyers trying to find the most accurate answer from their contracts are willing to wait a few more seconds to get the answer instead of getting wrong answers fast.

## Objective

This notebook, we will explore how we can build a simple agentic RAG using Cohere's native API. We have prepared a fake dataset to demonstrate the use case.
We ask three questions that require different depths of retrieval. We will see how the model answers the question between simple and agentic RAG.

## Disclaimer

One of the challenges in building a RAG system is that it has many moving pieces: vector database, type of embedding model, use of reranker, number of retrieved documents, chunking strategy, and more. These components can make debugging and evaluating RAG systems difficult. Since this notebook focuses on the concept of agentic RAG, it will simplify other parts of the RAG system. For example, we will only retrieve top 1 document to demonstrate what happens when retrieved document does not contain the answer needed.

## Result

| Type                   | Question                                                  | Simple Rag                                                                                                                                                                                       | Agentic Rag                                                                                                                  |
| ---------------------- | --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------- |
| Single-stage retrieval | Is there a state level law for wearing helmets?           | There is currently no state law requiring the use of helmets when riding a bicycle. However, some cities and counties do require helmet use.                                                     | There is currently no state law requiring helmet use. However, some cities and counties do require helmet use with bicycles. |
| Multi-stage retrieval  | I live in orting, do I need to wear a helmet with a bike? | In the state of Washington, there is no law requiring you to wear a helmet when riding a bike. However, some cities and counties do require helmet use, so it is worth checking your local laws. | Yes, you do need to wear a helmet with a bike in Orting if you are under 17.                                                 |

As you will see more below, the multi-stage retrieval is achieved by adding a new function `reference_extractor()` that extracts other references in the documents and updating the instruction so the agent continues to retrieve more documents.

```python PYTHON
import os
from pprint import pprint

import cohere
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
```

```python PYTHON
# versions
print('cohere version:', cohere.__version__)
```

```txt title="Output"
cohere version: 5.5.1
```

## Setup

```python PYTHON
COHERE_API_KEY = os.environ.get("CO_API_KEY")
COHERE_MODEL = 'command-a-03-2025'
co = cohere.Client(api_key=COHERE_API_KEY)
```

## Data

We leveraged data from [Washington Department of Transportation](https://wsdot.wa.gov/travel/bicycling-walking/bicycling-washington/bicyclist-laws-safety) and modified to fit the need of this demo.

```python PYTHON
documents = [
    {
        "title": "Bicycle law",
        "body": """
        Traffic Infractions and fees - For all information related to bicycle traffic infractions such as not wearing a helmet and fee information, please visit Section 3b for more information.
        Riding on the road - When riding on a roadway, a cyclist has all the rights and responsibilities of a vehicle driver (RCW 46.61.755). Bicyclists who violate traffic laws may be ticketed (RCW 46.61.750).
        Roads closed to bicyclists - Some designated sections of the state's limited access highway system may be closed to bicyclists. See the permanent bike restrictions map for more information. In addition, local governments may adopt ordinances banning cycling on specific roads or on sidewalks within business districts.
        Children bicycling - Parents or guardians may not knowingly permit bicycle traffic violations by their ward (RCW 46.61.700).
        Riding side by side - Bicyclists may ride side by side, but not more than two abreast (RCW 46.61.770).
        Riding at night - For night bicycle riding, a white front light (not a reflector) visible for 500 feet and a red rear reflector are required. A red rear light may be used in addition to the required reflector (RCW 46.61.780).
        Shoulder vs. bike lane - Bicyclists may choose to ride on the path, bike lane, shoulder or travel lane as suits their safety needs (RCW 46.61.770).
        Bicycle helmets - Currently, there is no state law requiring helmet use. However, some cities and counties do require helmets. For specific information along with location for bicycle helmet law please reference to section 21a.
        Bicycle equipment - Bicycles must be equipped with a white front light visible for 500 feet and a red rear reflector (RCW 46.61.780). A red rear light may be used in addition to the required reflector.
""",
    },
    {
        "title": "Bicycle helmet requirement",
        "body": "Currently, there is no state law requiring helmet use. However, some cities and counties do require helmet use with bicycles. Here is a list of those locations and when the laws were enacted. For specific information along with location for bicycle helmet law please reference to section 21a.",
    },
    {
        "title": "Section 21a",
        "body": """helmet rules by location: These are city and county level rules. The following group must wear helmets.
        Location name | Who is affected | Effective date
        Aberdeen | All ages | 2001
        Bainbridge Island | All ages | 2001
        Bellevue | All ages | 2001
        Bremerton | All ages | 2000
        DuPont | All ages | 2008
        Eatonville | All ages | 1996
        Fircrest | All ages | 1995
        Gig Harbor | All ages | 1996
        Kent | All ages | 1999
        Lynnwood | All ages | 2004
        Lakewood | All ages | 1996
        Milton | All ages | 1997
        Orting | Under 17 | 1997

     For fines and rules, you will be charged in according with Section 3b of the law.
     """,
    },
    {
        "title": "Section 3b",
        "body": """Traffic infraction - A person operating a bicycle upon a roadway or highway shall be subject to the provisions of this chapter relating to traffic infractions.
        1. Stop for people in crosswalks. Every intersection is a crosswalk - Itâ€™s the law. Drivers must stop for pedestrians at intersections, whether itâ€™s an unmarked or marked crosswalk, and bicyclists in crosswalks are considered pedestrians. Also, it is illegal to pass another vehicle stopped for someone at a crosswalk. In Washington, the leading action motorists take that results in them hitting someone is a failure to yield to pedestrians.
        2. Put the phone down. Hand-held cell phone use and texting is prohibited for all Washington drivers and may result in a $136 fine for first offense, $235 on the second distracted-driving citation.
        3. Helmets are required for all bicyclists according to the state and municipal laws. If you are in a group required to wear a helmet but do not wear it you can be fined $48. # If you are the parent or legal guardian of a child under 17 and knowingly allow them to ride without a helmet, you can be fined $136.
""",
    },
]
db = pd.DataFrame(documents)
# comebine title and body
db["combined"] = "Title: " + db["title"] + "\n" + "Body: " + db["body"]
# generate embedding
embeddings = co.embed(
    texts=db.combined.tolist(), model="embed-v4.0", input_type="search_document"
)
db["embeddings"] = embeddings.embeddings

```

```python PYTHON
db
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          title
        </th>

        <th>
          body
        </th>

        <th>
          combined
        </th>

        <th>
          embeddings
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          0
        </th>

        <td>
          Bicycle law
        </td>

        <td>
          \n Traffic Infractions and fees - For a...
        </td>

        <td>
          Title: Bicycle law\nBody: \n Traffic In...
        </td>

        <td>
          \[-0.024673462, -0.034729004, 0.0418396, 0.0121...
        </td>
      </tr>

      <tr>
        <th>
          1
        </th>

        <td>
          Bicycle helmet requirement
        </td>

        <td>
          Currently, there is no state law requiring hel...
        </td>

        <td>
          Title: Bicycle helmet requirement\nBody: Curre...
        </td>

        <td>
          \[-0.019180298, -0.037384033, 0.0027389526, -0....
        </td>
      </tr>

      <tr>
        <th>
          2
        </th>

        <td>
          Section 21a
        </td>

        <td>
          helmet rules by location: These are city and c...
        </td>

        <td>
          Title: Section 21a\nBody: helmet rules by loca...
        </td>

        <td>
          \[0.031097412, 0.0007619858, -0.023010254, -0.0...
        </td>
      </tr>

      <tr>
        <th>
          3
        </th>

        <td>
          Section 3b
        </td>

        <td>
          Traffic infraction - A person operating a bicy...
        </td>

        <td>
          Title: Section 3b\nBody: Traffic infraction - ...
        </td>

        <td>
          \[0.015602112, -0.016143799, 0.032958984, 0.000...
        </td>
      </tr>
    </tbody>
  </table>
</div>

## Tools

Following functions and tools will be used in the subsequent tasks.

```python PYTHON
def retrieve_documents(query: str, n=1) -> dict:
    """
    Function to retrieve documents a given query.

    Steps:
    1. Embed the query
    2. Calculate cosine similarity between the query embedding and the embeddings of the documents
    3. Return the top n documents with the highest similarity scores
    """
    query_emb = co.embed(
        texts=[query], model="embed-v4.0", input_type="search_query"
    )

    similarity_scores = cosine_similarity(
        [query_emb.embeddings[0]], db.embeddings.tolist()
    )
    similarity_scores = similarity_scores[0]

    top_indices = similarity_scores.argsort()[::-1][:n]
    top_matches = db.iloc[top_indices]

    return {"top_matched_document": top_matches.combined}


functions_map = {
    "retrieve_documents": retrieve_documents,
}

tools = [
    {
        "name": "retrieve_documents",
        "description": "given a query, retrieve documents from a database to answer user's question",
        "parameter_definitions": {
            "query": {"description": "query", "type": "str", "required": True}
        },
    }
]

```

## RAG function

```python PYTHON
def simple_rag(query, db):
    """
    Given user's query, retrieve top documents and generate response using documents parameter.
    """
    top_matched_document = retrieve_documents(query)["top_matched_document"]

    print("top_matched_document", top_matched_document)

    output = co.chat(
        message=query, model=COHERE_MODEL, documents=[top_matched_document]
    )

    return output.text

```

## Agentic RAG - cohere\_agent()

```python PYTHON
def cohere_agent(
    message: str,
    preamble: str,
    tools: list[dict],
    force_single_step=False,
    verbose: bool = False,
    temperature: float = 0.3,
) -> str:
    """
    Function to handle multi-step tool use api.

    Args:
        message (str): The message to send to the Cohere AI model.
        preamble (str): The preamble or context for the conversation.
        tools (list of dict): List of tools to use in the conversation.
        verbose (bool, optional): Whether to print verbose output. Defaults to False.

    Returns:
        str: The final response from the call.
    """

    counter = 1

    response = co.chat(
        model=COHERE_MODEL,
        message=message,
        preamble=preamble,
        tools=tools,
        force_single_step=force_single_step,
        temperature=temperature,
    )

    if verbose:
        print(f"\nrunning 0th step.")
        print(response.text)

    while response.tool_calls:
        tool_results = []

        if verbose:
            print(f"\nrunning {counter}th step.")

        for tool_call in response.tool_calls:
            output = functions_map[tool_call.name](**tool_call.parameters)
            outputs = [output]
            tool_results.append({"call": tool_call, "outputs": outputs})

            if verbose:
                print(
                    f"= running tool {tool_call.name}, with parameters: \n{tool_call.parameters}"
                )
                print(f"== tool results:")
                pprint(output)

        response = co.chat(
            model=COHERE_MODEL,
            message="",
            chat_history=response.chat_history,
            preamble=preamble,
            tools=tools,
            force_single_step=force_single_step,
            tool_results=tool_results,
            temperature=temperature,
        )

        if verbose:
            print(response.text)
            counter += 1

    return response.text

```

## Question 1 - single-stage retrieval

Here we are asking a question that can be answered easily with single-stage retrieval. Both regular and agentic RAG should be able to answer this question easily. Below is the comparsion of the response.

| Question                                        | Simple Rag                                                                                                                                   | Agentic Rag                                                                                                                  |
| ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| Is there a state level law for wearing helmets? | There is currently no state law requiring the use of helmets when riding a bicycle. However, some cities and counties do require helmet use. | There is currently no state law requiring helmet use. However, some cities and counties do require helmet use with bicycles. |

```python PYTHON
question1 = "Is there a state level law for wearing helmets?"
```

### Simple RAG

```python PYTHON
output = simple_rag(question1, db)
print(output)
```

```txt title="Output"
top_matched_document 1    Title: Bicycle helmet requirement\nBody: Curre...
Name: combined, dtype: object
There is currently no state law requiring the use of helmets when riding a bicycle. However, some cities and counties do require helmet use.
```

### Agentic RAG

```python PYTHON
preamble = """
You are an expert assistant that helps users answers question about legal documents and policies.
Use the provided documents to answer questions about an employee's specific situation.
"""

output = cohere_agent(question1, preamble, tools, verbose=True)
```

```txt title="Output"
running 0th step.
I will search for 'state level law for wearing helmets' in the documents provided and write an answer based on what I find.

running 1th step.
= running tool retrieve_documents, with parameters:
{'query': 'state level law for wearing helmets'}
== tool results:
{'top_matched_document': 1    Title: Bicycle helmet requirement\nBody: Curre...
Name: combined, dtype: object}
There is currently no state law requiring helmet use. However, some cities and counties do require helmet use with bicycles.
```

## Question 2 - double-stage retrieval

The second question requires a double-stage retrieval because top matched document references another document. You will see below that the agentic RAG is unable to produce the correct answer initially. But when given proper tools and instructions, it finds the correct answer.

| Question                                                  | Simple Rag                                                                                                                                                                                       | Agentic Rag                                                                  |
| --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------- |
| I live in orting, do I need to wear a helmet with a bike? | In the state of Washington, there is no law requiring you to wear a helmet when riding a bike. However, some cities and counties do require helmet use, so it is worth checking your local laws. | Yes, you do need to wear a helmet with a bike in Orting if you are under 17. |

```python PYTHON
question2 = "I live in orting, do I need to wear a helmet with a bike?"
```

### Simple RAG

```python PYTHON
output = simple_rag(question2, db)
print(output)
```

```txt title="Output"
top_matched_document 1    Title: Bicycle helmet requirement\nBody: Curre...
Name: combined, dtype: object
In the state of Washington, there is no law requiring you to wear a helmet when riding a bike. However, some cities and counties do require helmet use, so it is worth checking your local laws.
```

### Agentic RAG

Produces same quality answer as the simple rag.

```python PYTHON
preamble = """
You are an expert assistant that helps users answers question about legal documents and policies.
Use the provided documents to answer questions about an employee's specific situation.
"""

output = cohere_agent(question2, preamble, tools, verbose=True)
```

```txt title="Output"
running 0th step.
I will search for 'helmet with a bike' and then write an answer.

running 1th step.
= running tool retrieve_documents, with parameters:
{'query': 'helmet with a bike'}
== tool results:
{'top_matched_document': 1    Title: Bicycle helmet requirement\nBody: Curre...
Name: combined, dtype: object}
There is no state law requiring helmet use, however, some cities and counties do require helmet use with bicycles. I cannot find any information about Orting specifically, but you should check with your local authority.
```

### Agentic RAG - New Tools

In order for the model to retrieve correct documents, we do two things:

1. New reference\_extractor() function is added. This function finds the references to other documents when given query and documents.
2. We update the instruction that directs the agent to keep retrieving relevant documents.

```python PYTHON
def reference_extractor(query: str, documents: list[str]) -> str:
    """
    Given a query and document, find references to other documents.
    """
    prompt = f"""
    # instruction
    Does the reference document mention any other documents? If so, list them.
    If not, return empty string.

    # user query
    {query}

    # retrieved documents
    {documents}
    """

    return co.chat(message=prompt, model=COHERE_MODEL, preamble=None).text


def retrieve_documents(query: str, n=1) -> dict:
    """
    Function to retrieve most relevant documents a given query.
    It also returns other references mentioned in the top matched documents.
    """
    query_emb = co.embed(
        texts=[query], model="embed-v4.0", input_type="search_query"
    )

    similarity_scores = cosine_similarity(
        [query_emb.embeddings[0]], db.embeddings.tolist()
    )
    similarity_scores = similarity_scores[0]

    top_indices = similarity_scores.argsort()[::-1][:n]
    top_matches = db.iloc[top_indices]
    other_references = reference_extractor(query, top_matches.combined.tolist())

    return {
        "top_matched_document": top_matches.combined,
        "other_references_to_query": other_references,
    }


functions_map = {
    "retrieve_documents": retrieve_documents,
}

tools = [
    {
        "name": "retrieve_documents",
        "description": "given a query, retrieve documents from a database to answer user's question. It also finds references to other documents that should be leveraged to retrieve more documents",
        "parameter_definitions": {
            "query": {
                "description": "user's question or question or name of other document sections or references.",
                "type": "str",
                "required": True,
            }
        },
    }
]

```

```python PYTHON
preamble2 = """# Instruction
You are an expert assistant that helps users answer questions about legal documents and policies.

Please follow these steps:
1. Using user's query, use `retrieve_documents` tool to retrieve the most relevant document from the database.
2. If you see `other_references_to_query` in the tool result, search the mentioned referenced using `retrieve_documents(<other reference="">)` tool to retrieve more documents.
3. Keep trying until you find the answer.
4. Answer with yes or no as much as you can to answer the question directly.
"""

output = cohere_agent(question2, preamble2, tools, verbose=True)
```

```txt title="Output"
running 0th step.
I will search for 'Orting' and 'bike helmet' to find the relevant information.

running 1th step.
= running tool retrieve_documents, with parameters:
{'query': 'Orting bike helmet'}
== tool results:
{'other_references_to_query': 'Section 21a, Section 3b',
    'top_matched_document': 0    Title: Bicycle law\nBody: \n        Riding on ...
Name: combined, dtype: object}
I have found that there is no state law requiring helmet use, but some cities and counties do require helmets. I will now search for 'Section 21a' to find out if Orting is one of these cities or counties.

running 2th step.
= running tool retrieve_documents, with parameters:
{'query': 'Section 21a'}
== tool results:
{'other_references_to_query': '- Section 3b',
    'top_matched_document': 2    Title: Section 21a\nBody: helmet rules by loca...
Name: combined, dtype: object}
Yes, you do need to wear a helmet when riding a bike in Orting if you are under 17.
```


# Agentic RAG for PDFs with mixed data

> This page describes building a powerful, multi-step chatbot with Cohere's models.

<AuthorsContainer
  authors={[
    {
      name: "Shaan Desai",
      imageSrc: "https://fern-image-hosting.s3.amazonaws.com/cohere/d17fc44-Shaan.jpg",
    },
  ]}
/>

<CookbookHeader href="https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/agents/agentic-RAG/agentic_rag_langchain.ipynb" />

## Motivation

Retrieval-augmented generation (RAG) allows language models to generate grounded answers to questions about documents. However, the complexity of the documents can significantly influence overall RAG performance. For instance, the documents may be PDFs that contain a mix of text and tables.

More broadly, the implementation of a RAG pipeline - including parsing and chunking of documents, along with the embedding and retrieval of the chunks - is critical to the accuracy of grounded answers. Additionally, it is sometimes not sufficient to merely retrieve the answers; a user may want further postprocessing performed on the output. This use case would benefit from giving the model access to tools.

## Objective

In this notebook, we will guide you through best practices for setting up a RAG pipeline to process documents that contain both tables and text. We will also demonstrate how to create a [ReAct](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/react/) agent with a Cohere model, and then give the agent access to a RAG pipeline tool to improve accuracy. The general structure of the notebook is as follows:

* individual components around parsing, retrieval and generation are covered for documents with mixed tabular and textual data
* a class object is created that can be used to instantiate the pipeline with parametric input
* the RAG pipeline is then used as a tool for a Cohere ReACT agent

# Reference Documents

We recommend the following notebook as a guide to [semi-structured RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb).

We also recommend the following notebook to explore various parsing techniques for [PDFs](https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Document_Parsing_For_Enterprises.ipynb).

Various LangChain-supported parsers can be found [here](https://python.langchain.com/docs/how_to/document_loader_pdf/).

## Install Dependencies

```python PYTHON
# there may be other dependencies that will need installation
# ! pip install --quiet langchain langchain_cohere langchain_experimental
# !pip --quiet install faiss-cpu tiktoken
# !pip install pypdf
# !pip install pytesseract
# !pip install opencv-python --upgrade
# !pip install "unstructured[all-docs]"
# !pip install chromadb
```

```python PYTHON
# LLM
import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS
from langchain_cohere import CohereEmbeddings
from pydantic import BaseModel
from unstructured.partition.pdf import partition_pdf
from langchain_community.document_loaders import PyPDFLoader
import os
from typing import Any
import uuid
from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain.storage import InMemoryStore
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
import cohere, json
import pandas as pd
from datasets import load_dataset
from joblib import Parallel, delayed

os.environ['COHERE_API_KEY'] = ""
```

# Parsing \[#sec\_step1]

To improve RAG performance on PDFs with mixed types (text and tables), we investigated a number of parsing and chunking strategies from various libraries:

* [PyPDFLoader (LC)](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html)
* [LlamaParse](https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/) (Llama-Index)
* [Unstructured](https://unstructured.io/)

We have found that the best option for parsing is unstructured.io since the parser can:

* separate tables from text
* automatically chunk the tables and text by title during the parsing step so that similar elements are grouped

```python PYTHON
# UNSTRUCTURED pdf loader
# Get elements
raw_pdf_elements = partition_pdf(
    filename="city_ny_popular_fin_report.pdf",
    # Unstructured first finds embedded image blocks
    extract_images_in_pdf=False,
    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles
    # Titles are any sub-section of the document
    infer_table_structure=True,
    # Post processing to aggregate text once we have the title
    chunking_strategy="by_title",
    # Chunking params to aggregate text blocks
    # Attempt to create a new chunk 3800 chars
    # Attempt to keep chunks > 2000 chars
    max_characters=4000,
    new_after_n_chars=3800,
    combine_text_under_n_chars=2000,
    image_output_dir_path='.',
)

```

```python PYTHON
# extract table and textual objects from parser
class Element(BaseModel):
    type: str
    text: Any

# Categorize by type
categorized_elements = []
for element in raw_pdf_elements:
    if "unstructured.documents.elements.Table" in str(type(element)):
        categorized_elements.append(Element(type="table", text=str(element)))
    elif "unstructured.documents.elements.CompositeElement" in str(type(element)):
        categorized_elements.append(Element(type="text", text=str(element)))

# Tables
table_elements = [e for e in categorized_elements if e.type == "table"]
print(len(table_elements))

# Text
text_elements = [e for e in categorized_elements if e.type == "text"]
print(len(text_elements))
```

```txt title="Output"
14
24
```

# Vector Store Setup \[#sec\_step2]

There are many options for setting up a vector store. Here, we show how to do so using [Chroma](https://www.trychroma.com/) and Langchain's Multi-vector retrieval.
As the name implies, multi-vector retrieval allows us to store multiple vectors per document; for instance, for a single document chunk, one could keep embeddings for both the chunk itself, and a summary of that document. A summary may be able to distill more accurately what a chunk is about, leading to better retrieval.

You can read more about this here: [https://python.langchain.com/docs/how\_to/multi\_vector/](https://python.langchain.com/docs/how_to/multi_vector/)

Below, we demonstrate the following process:

* summaries of each chunk are embedded
* during inference, the multi-vector retrieval returns the full context document related to the summary

```python PYTHON
co = cohere.Client()
def get_chat_output(message, preamble, chat_history, model, temp, documents=None):
    return co.chat(
    message=message,
    preamble=preamble,
    chat_history=chat_history,
    documents=documents,
    model=model,
    temperature=temp
    ).text

def parallel_proc_chat(prompts,preamble,chat_history=None,model='command-a-03-2025',temp=0.1,n_jobs=10):
    """Parallel processing of chat endpoint calls."""
    responses = Parallel(n_jobs=n_jobs, prefer="threads")(delayed(get_chat_output)(prompt,preamble,chat_history,model,temp) for prompt in prompts)
    return responses

def rerank_cohere(query, returned_documents,model:str="rerank-multilingual-v3.0",top_n:int=3):
    response = co.rerank(
        query=query,
        documents=returned_documents,
        top_n=top_n,
        model=model,
        return_documents=True
    )
    top_chunks_after_rerank = [results.document.text for results in response.results]
    return top_chunks_after_rerank

```

```python PYTHON
# generate table and text summaries
prompt_text = """You are an assistant tasked with summarizing tables and text. \
Give a concise summary of the table or text. Table or text chunk: {element}. Only provide the summary and no other text."""

table_prompts = [prompt_text.format(element=i.text) for i in table_elements]
table_summaries = parallel_proc_chat(table_prompts,None)
text_prompts = [prompt_text.format(element=i.text) for i in text_elements]
text_summaries = parallel_proc_chat(text_prompts,None)
tables = [i.text for i in table_elements]
texts = [i.text for i in text_elements]
```

```python PYTHON
# The vectorstore to use to index the child chunks
vectorstore = Chroma(collection_name="summaries", embedding_function=CohereEmbeddings())
# The storage layer for the parent documents
store = InMemoryStore()
id_key = "doc_id"
# The retriever (empty to start)
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key=id_key,
)
# Add texts
doc_ids = [str(uuid.uuid4()) for _ in texts]
summary_texts = [
    Document(page_content=s, metadata={id_key: doc_ids[i]})
    for i, s in enumerate(text_summaries)
]
retriever.vectorstore.add_documents(summary_texts)
retriever.docstore.mset(list(zip(doc_ids, texts)))
# Add tables
table_ids = [str(uuid.uuid4()) for _ in tables]
summary_tables = [
    Document(page_content=s, metadata={id_key: table_ids[i]})
    for i, s in enumerate(table_summaries)
]
retriever.vectorstore.add_documents(summary_tables)
retriever.docstore.mset(list(zip(table_ids, tables)))
```

# RAG Pipeline \[#sec\_step3]

With our database in place, we can run queries against it. The query process can be broken down into the following steps:

* augment the query, this really helps retrieve all the relevant information
* use each augmented query to retrieve the top k docs and then rerank them
* concatenate all the shortlisted/reranked docs and pass them to the generation model

```python PYTHON
def process_query(query, retriever):
    """Runs query augmentation, retrieval, rerank and final generation in one call."""
    augmented_queries=co.chat(message=query,model='command-a-03-2025',temperature=0.2, search_queries_only=True)
        #augment queries
    if augmented_queries.search_queries:
        reranked_docs=[]
        for itm in augmented_queries.search_queries:
            docs=retriever.invoke(itm.text)
            temp_rerank = rerank_cohere(itm.text,docs)
            reranked_docs.extend(temp_rerank)
        documents = [{"title": f"chunk {i}", "snippet": reranked_docs[i]} for i in range(len(reranked_docs))]
    else:
        #no queries will be run through RAG
        documents = None

    preamble = """
## Task &amp; Context
You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.

## Style Guide
Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.
"""
    model = 'command-a-03-2025'
    temp = 0.2



    response = co.chat(
      message=query,
      documents=documents,
      preamble=preamble,
      model=model,
      temperature=temp
    )

    final_answer_docs="""The final answer is from the documents below:

    {docs}""".format(docs=str(response.documents))

    final_answer = response.text
    return final_answer, final_answer_docs
```

## Example

We can now test out a query. In this example, the final answer can be found on page 12 of the PDF, which aligns with the response provided by the model:

```python PYTHON
query = "what are the charges for services in 2022"
final_answer, final_answer_docs = process_query(query, retriever)
print(final_answer)
print(final_answer_docs)


chat_history=[{'role':"USER", 'message':query},{'role':"CHATBOT", 'message':f'The final answer is: {final_answer}.' + final_answer_docs}]
```

```txt title="Output"
The charges for services in 2022 were $5,266 million.
The final answer is from the documents below:

    [{'id': 'doc_0', 'snippet': 'Program and General Revenues FY 2023 FY 2022 FY 2021 Category (in millions) Charges for Services (CS) $5,769 $5,266 $5,669 Operating Grants and Contributions (OGC) 27,935 31,757 28,109 Capital Grants and Contributions (CGC) 657 656 675 Real Estate Taxes (RET) 31,502 29,507 31,421 Sales and Use Taxes (SUT) 10,577 10,106 7,614 Personal Income Taxes (PIT) 15,313 15,520 15,795 Income Taxes, Other (ITO) 13,181 9,521 9,499 Other Taxes* (OT) 3,680 3,777 2,755 Investment Income* (II) 694 151 226 Unrestricted Federal and State Aid (UFSA) 234 549 108 Other* (O) Total Program and General Revenues - Primary Government 2,305 $110,250 $107,535 $104,176 708 725', 'title': 'chunk 0'}]
```

### Chat History Management

In the example below, we ask a follow up question that relies on the chat history, but does not require a rerun of the RAG pipeline.

We detect questions that do not require RAG by examining the `search_queries` object returned by calling `co.chat` to generate candidate queries to answer our question. If this object is empty, then the model has determined that a document query is not needed to answer the question.

In the example below, the `else` statement is invoked based on `query2`. We still pass in the chat history, allowing the question to be answered with only the prior context.

```python PYTHON
query2='divide this by two'
augmented_queries=co.chat(message=query2,model='command-a-03-2025',temperature=0.2, search_queries_only=True)
if augmented_queries.search_queries:
    print('RAG is needed')
    final_answer, final_answer_docs = process_query(query, retriever)
    print(final_answer)
else:
    print('RAG is not needed')
    response = co.chat(
      message=query2,
      model='command-a-03-2025',
      chat_history=chat_history,
      temperature=0.3
    )

    print("Final answer:")
    print(response.text)
```

```txt title="Output"
    RAG is not needed
    Final answer:
    The result of dividing the charges for services in 2022 by two is $2,633.
```

***

# RAG Pipeline Class \[#sec\_step4]

Here, we connect all of the pieces discussed above into one class object, which is then used as a tool for a Cohere ReAct agent. This class definition consolidates and clarify the key parameters used to define the RAG pipeline.

```python PYTHON
co = cohere.Client()
```

```python PYTHON
class Element(BaseModel):
    type: str
    text: Any

class RAG_pipeline():
    def __init__(self,paths):
        self.embedding_model="embed-v4.0"
        self.generation_model="command-a-03-2025"
        self.summary_model="command-a-03-2025"
        self.rerank_model="rerank-multilingual-v3.0"
        self.num_docs_to_retrieve = 10
        self.top_k_rerank=3
        self.temperature=0.2
        self.preamble="""
## Task &amp; Context
You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.

## Style Guide
Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.
"""
        self.n_jobs=10 #number of parallel processes to run summarization of chunks
        self.extract_images_in_pdf=False
        self.infer_table_structure=True
        self.chunking_strategy="by_title"
        self.max_characters=4000
        self.new_after_n_chars=3800
        self.combine_text_under_n_chars=2000
        self.image_output_dir_path='.'
        self.paths = paths
        self.parse_and_build_retriever()

    def parse_and_build_retriever(self,):
        #step1, parse pdfs
        # if condition just for debugging since perf_audit.pdf is parsed in the prev step, no need to rerun
        parsed_pdf_list=self.parse_pdfs(self.paths)
        #separate tables and text
        extracted_tables, extracted_text = self.extract_text_and_tables(parsed_pdf_list)
        #generate summaries for everything
        tables, table_summaries, texts, text_summaries=self.generate_summaries(extracted_tables,extracted_text)
        self.tables = tables
        self.table_summaries = table_summaries
        self.texts = texts
        self.text_summaries=text_summaries
        #setup the multivector retriever
        self.make_retriever(tables, table_summaries, texts, text_summaries)

    def extract_text_and_tables(self,parsed_pdf_list):
        # extract table and textual objects from parser
        # Categorize by type
        all_table_elements = []
        all_text_elements = []
        for raw_pdf_elements in parsed_pdf_list:
            categorized_elements = []
            for element in raw_pdf_elements:
                if "unstructured.documents.elements.Table" in str(type(element)):
                    categorized_elements.append(Element(type="table", text=str(element)))
                elif "unstructured.documents.elements.CompositeElement" in str(type(element)):
                    categorized_elements.append(Element(type="text", text=str(element)))

            # Tables
            table_elements = [e for e in categorized_elements if e.type == "table"]
            print(len(table_elements))

            # Text
            text_elements = [e for e in categorized_elements if e.type == "text"]
            print(len(text_elements))
            all_table_elements.extend(table_elements)
            all_text_elements.extend(text_elements)

        return all_table_elements, all_text_elements

    def parse_pdfs(self, paths):

        path_raw_elements = []
        for path in paths:
            raw_pdf_elements = partition_pdf(
            filename=path,
            # Unstructured first finds embedded image blocks
            extract_images_in_pdf=self.extract_images_in_pdf,
            # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles
            # Titles are any sub-section of the document
            infer_table_structure=self.infer_table_structure,
            # Post processing to aggregate text once we have the title
            chunking_strategy=self.chunking_strategy,
            # Chunking params to aggregate text blocks
            # Attempt to create a new chunk 3800 chars
            # Attempt to keep chunks > 2000 chars
            max_characters=self.max_characters,
            new_after_n_chars=self.new_after_n_chars,
            combine_text_under_n_chars=self.combine_text_under_n_chars,
            image_output_dir_path=self.image_output_dir_path,
            )
            path_raw_elements.append(raw_pdf_elements)
        print('PDFs parsed')
        return path_raw_elements


    def get_chat_output(self,message, preamble, model, temp):
        # print("**message")
        # print(message)

        response=co.chat(
            message=message,
            preamble=preamble,
            model=model,
            temperature=temp
            ).text
        # print("**output")
        # print(response)
        return response

    def parallel_proc_chat(self,prompts,preamble,model,temp,n_jobs):
        """Parallel processing of chat endpoint calls."""
        responses = Parallel(n_jobs=n_jobs, prefer="threads")(delayed(self.get_chat_output)(prompt,preamble,model,temp) for prompt in prompts)
        return responses

    def rerank_cohere(self,query, returned_documents,model, top_n):
        response = co.rerank(
            query=query,
            documents=returned_documents,
            top_n=top_n,
            model=model,
            return_documents=True
        )
        top_chunks_after_rerank = [results.document.text for results in response.results]
        return top_chunks_after_rerank

    def generate_summaries(self,table_elements,text_elements):
        # generate table and text summaries

        summarize_prompt = """You are an assistant tasked with summarizing tables and text. \
        Give a concise summary of the table or text. Table or text chunk: {element}. Only provide the summary and no other text."""

        table_prompts = [summarize_prompt.format(element=i.text) for i in table_elements]
        table_summaries = self.parallel_proc_chat(table_prompts,self.preamble,self.summary_model,self.temperature,self.n_jobs)
        text_prompts = [summarize_prompt.format(element=i.text) for i in text_elements]
        text_summaries = self.parallel_proc_chat(text_prompts,self.preamble,self.summary_model,self.temperature,self.n_jobs)
        tables = [i.text for i in table_elements]
        texts = [i.text for i in text_elements]
        print('summaries generated')
        return tables, table_summaries, texts, text_summaries

    def make_retriever(self,tables, table_summaries, texts, text_summaries):
        # The vectorstore to use to index the child chunks
        vectorstore = Chroma(collection_name="summaries", embedding_function=CohereEmbeddings())
        # The storage layer for the parent documents
        store = InMemoryStore()
        id_key = "doc_id"
        # The retriever (empty to start)
        retriever = MultiVectorRetriever(
            vectorstore=vectorstore,
            docstore=store,
            id_key=id_key,
            search_kwargs={"k": self.num_docs_to_retrieve}
        )
        # Add texts
        doc_ids = [f'text_{i}' for i in range(len(texts))]#[str(uuid.uuid4()) for _ in texts]
        summary_texts = [
            Document(page_content=s, metadata={id_key: doc_ids[i]})
            for i, s in enumerate(text_summaries)
        ]
        retriever.vectorstore.add_documents(summary_texts,ids=doc_ids)
        retriever.docstore.mset(list(zip(doc_ids, texts)))
        # Add tables
        table_ids = [f'table_{i}' for i in range(len(texts))]#[str(uuid.uuid4()) for _ in tables]
        summary_tables = [
            Document(page_content=s, metadata={id_key: table_ids[i]})
            for i, s in enumerate(table_summaries)
        ]
        retriever.vectorstore.add_documents(summary_tables,ids=table_ids)
        retriever.docstore.mset(list(zip(table_ids, tables)))
        self.retriever = retriever
        print('retriever built')

    def process_query(self,query):
        """Runs query augmentation, retrieval, rerank and generation in one call."""
        augmented_queries=co.chat(message=query,model=self.generation_model,temperature=self.temperature, search_queries_only=True)
        #augment queries
        if augmented_queries.search_queries:
            reranked_docs=[]
            for itm in augmented_queries.search_queries:
                docs=self.retriever.invoke(itm.text)
                temp_rerank = self.rerank_cohere(itm.text,docs,model=self.rerank_model,top_n=self.top_k_rerank)
                reranked_docs.extend(temp_rerank)
            documents = [{"title": f"chunk {i}", "snippet": reranked_docs[i]} for i in range(len(reranked_docs))]
        else:
            documents = None

        response = co.chat(
          message=query,
          documents=documents,
          preamble=self.preamble,
          model=self.generation_model,
          temperature=self.temperature
        )

        final_answer_docs="""The final answer is from the documents below:

        {docs}""".format(docs=str(response.documents))

        final_answer = response.text
        return final_answer, final_answer_docs

```

```python PYTHON
rag_object=RAG_pipeline(paths=["city_ny_popular_fin_report.pdf"])
```

This function will be deprecated in a future release and `unstructured` will simply use the DEFAULT\_MODEL from `unstructured_inference.model.base` to set default model name

```txt title="Output"
PDFs parsed
14
24
summaries generated
retriever built
```

# Cohere ReAct Agent with RAG Tool \[#sec\_step5]

Finally, we build a simple agent that utilizes the RAG pipeline defined above. We do this by granting the agent access to two tools:

* the end-to-end RAG pipeline
* a Python interpreter

The intention behind coupling these tools is to enable the model to perform mathematical and other postprocessing operations on RAG outputs using Python.

```python PYTHON
from langchain.agents import Tool
from langchain_experimental.utilities import PythonREPL
from langchain.agents import AgentExecutor
from langchain_cohere.react_multi_hop.agent import create_cohere_react_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_cohere.chat_models import ChatCohere
from langchain.tools.retriever import create_retriever_tool
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.tools import tool

class react_agent():
    def __init__(self,rag_retriever,model="command-a-03-2025",temperature=0.2):
        self.llm = ChatCohere(model=model, temperature=temperature)
        self.preamble="""
## Task &amp; Context
You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.

## Style Guide
Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.

## Guidelines
You are an expert who answers the user's question.
You have access to a vectorsearch tool that will use your query to search through documents and find the relevant answer.
You also have access to a python interpreter tool which you can use to run code for mathematical operations.
"""
        self.get_tools(rag_retriever)
        self.build_agent()

    def get_tools(self,rag_retriever):
        @tool
        def vectorsearch(query: str):
            """Uses the query to search through a list of documents and return the most relevant documents as well as the answer."""
            final_answer, final_answer_docs=rag_retriever.process_query(query)
            return final_answer + final_answer_docs
        vectorsearch.name = "vectorsearch" # use python case
        vectorsearch.description = "Uses the query to search through a list of documents and return the most relevant documents as well as the answer."
        class vectorsearch_inputs(BaseModel):
            query: str = Field(description="the users query")
        vectorsearch.args_schema = vectorsearch_inputs


        python_repl = PythonREPL()
        python_tool = Tool(
            name="python_repl",
            description="Executes python code and returns the result. The code runs in a static sandbox without interactive mode, so print output or save output to a file.",
            func=python_repl.run,
        )
        python_tool.name = "python_interpreter"
        class ToolInput(BaseModel):
            code: str = Field(description="Python code to execute.")
        python_tool.args_schema = ToolInput

        self.alltools = [vectorsearch,python_tool]

    def build_agent(self):
        # Prompt template
        prompt = ChatPromptTemplate.from_template("{input}")
        # Create the ReAct agent
        agent = create_cohere_react_agent(
            llm=self.llm,
            tools=self.alltools,
            prompt=prompt,
        )
        self.agent_executor = AgentExecutor(agent=agent, tools=self.alltools, verbose=True,return_intermediate_steps=True)


    def run_agent(self,query,history=None):
        if history:
            response=self.agent_executor.invoke({
            "input": query,
            "preamble": self.preamble,
            "chat_history": history
        })
        else:
            response=self.agent_executor.invoke({
            "input": query,
            "preamble": self.preamble,
        })
        return response

```

```python PYTHON
agent_object=react_agent(rag_retriever=rag_object)
```

```python PYTHON
step1_response=agent_object.run_agent("what are the charges for services in 2022 and 2023")
```

```txt title="Output"
[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m
I will search for the charges for services in 2022 and 2023.
{'tool_name': 'vectorsearch', 'parameters': {'query': 'charges for services in 2022 and 2023'}}
[0m[36;1m[1;3mThe charges for services in 2022 were $5,266 million and in 2023 were $5,769 million.The final answer is from the documents below:

        [{'id': 'doc_0', 'snippet': 'Program and General Revenues FY 2023 FY 2022 FY 2021 Category (in millions) Charges for Services (CS) $5,769 $5,266 $5,669 Operating Grants and Contributions (OGC) 27,935 31,757 28,109 Capital Grants and Contributions (CGC) 657 656 675 Real Estate Taxes (RET) 31,502 29,507 31,421 Sales and Use Taxes (SUT) 10,577 10,106 7,614 Personal Income Taxes (PIT) 15,313 15,520 15,795 Income Taxes, Other (ITO) 13,181 9,521 9,499 Other Taxes* (OT) 3,680 3,777 2,755 Investment Income* (II) 694 151 226 Unrestricted Federal and State Aid (UFSA) 234 549 108 Other* (O) Total Program and General Revenues - Primary Government 2,305 $110,250 $107,535 $104,176 708 725', 'title': 'chunk 0'}][0m[32;1m[1;3mRelevant Documents: 0
Cited Documents: 0
Answer: The charges for services in 2022 were $5,266 million and in 2023 were $5,769 million.
Grounded answer: The charges for services in <co: 0="">2022</co:> were <co: 0="">$5,266 million</co:> and in <co: 0="">2023</co:> were <co: 0="">$5,769 million</co:>.[0m

[1m> Finished chain.[0m
```

Just like earlier, we can also pass chat history to the LangChain agent to refer to for any other queries.

```python PYTHON
from langchain_core.messages import HumanMessage, AIMessage
```

```python PYTHON
chat_history=[
HumanMessage(content=step1_response['input']),
AIMessage(content=step1_response['output'])
]
```

```python PYTHON
agent_object.run_agent("what is the mean of the two values",history=chat_history)
```

```txt title="Output"
[1m> Entering new AgentExecutor chain...[0m


Python REPL can execute arbitrary code. Use with caution.


[32;1m[1;3m
I will use the Python Interpreter tool to calculate the mean of the two values.
{'tool_name': 'python_interpreter', 'parameters': {'code': 'import numpy as np\n\n# Data\nvalues = [5266, 5769]\n\n# Calculate the mean\nmean_value = np.mean(values)\n\nprint(f"The mean of the two values is: {mean_value:.0f} million")'}}
[0m[33;1m[1;3mThe mean of the two values is: 5518 million
[0m[32;1m[1;3mRelevant Documents: 0
Cited Documents: 0
Answer: The mean of the two values is 5518 million.
Grounded answer: The mean of the two values is <co: 0="">5518 million</co:>.[0m

[1m> Finished chain.[0m
```

````python title="Output"
{'input': 'what is the mean of the two values',
'preamble': "\n## Task &amp; Context\nYou help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n\n## Style Guide\nUnless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n\n## Guidelines\nYou are an expert who answers the user's question. \nYou have access to a vectorsearch tool that will use your query to search through documents and find the relevant answer.\nYou also have access to a python interpreter tool which you can use to run code for mathematical operations.\n",
'chat_history': [HumanMessage(content='what are the charges for services in 2022 and 2023'),
AIMessage(content='The charges for services in 2022 were $5,266 million and in 2023 were $5,769 million.')],
'output': 'The mean of the two values is 5518 million.',
'citations': [CohereCitation(start=30, end=42, text='5518 million', documents=[{'output': 'The mean of the two values is: 5518 million\n'}])],
'intermediate_steps': [(AgentActionMessageLog(tool='python_interpreter', tool_input={'code': 'import numpy as np\n\n# Data\nvalues = [5266, 5769]\n\n# Calculate the mean\nmean_value = np.mean(values)\n\nprint(f"The mean of the two values is: {mean_value:.0f} million")'}, log='\nI will use the Python Interpreter tool to calculate the mean of the two values.\n{\'tool_name\': \'python_interpreter\', \'parameters\': {\'code\': \'import numpy as np\\n\\n# Data\\nvalues = [5266, 5769]\\n\\n# Calculate the mean\\nmean_value = np.mean(values)\\n\\nprint(f"The mean of the two values is: {mean_value:.0f} million")\'}}\n', message_log=[AIMessage(content='\nPlan: I will use the Python Interpreter tool to calculate the mean of the two values.\nAction: ```json\n[\n    {\n        "tool_name": "python_interpreter",\n        "parameters": {\n            "code": "import numpy as np\\n\\n# Data\\nvalues = [5266, 5769]\\n\\n# Calculate the mean\\nmean_value = np.mean(values)\\n\\nprint(f\\"The mean of the two values is: {mean_value:.0f} million\\")"\n        }\n    }\n]\n```')]),
'The mean of the two values is: 5518 million\n')]}
````

# Conclusion

As you can see, the RAG pipeline can be used as a tool for a Cohere ReAct agent. This allows the agent to access the RAG pipeline for document retrieval and generation, as well as a Python interpreter for postprocessing mathematical operations to improve accuracy. This setup can be used to improve the accuracy of grounded answers to questions about documents that contain both tables and text.


# Analysis of Form 10-K/10-Q Using Cohere and RAG

> This page describes how to use Cohere's large language models to build an agent able to analyze financial forms like a 10-K or a 10-Q.

<AuthorsContainer
  authors={[
    {
      name: "Alex Barbet",
      imageSrc: "https://fern-image-hosting.s3.amazonaws.com/cohere/bf2c763-Alex.jpg",
    },
  ]}
/>

<CookbookHeader href="https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Analysis_of_Form_10_K_Using_Cohere_and_RAG.ipynb" />

## **Getting Started**

You may use this script to jumpstart financial analysis of 10-Ks or 10-Qs with Cohere's Command model.

This cookbook relies on helpful tooling from LlamaIndex, as well as our Cohere SDK. If you're familiar with LlamaIndex, it should be easy to slot this process into your own productivity flows.

```python PYTHON
%%capture
!sudo apt install tesseract-ocr poppler-utils
!pip install "cohere<5" langchain llama-index llama-index-embeddings-cohere llama-index-postprocessor-cohere-rerank pytesseract pdf2image
```

```python PYTHON
# Due to compatibility issues, we need to do imports like this
from llama_index.core.schema import TextNode

%%capture
!pip install unstructured
```

```python PYTHON
import cohere
from getpass import getpass

# Set up Cohere client
COHERE_API_KEY = getpass("Enter your Cohere API key: ")

# Instantiate a client to communicate with Cohere's API using our Python SDK
co = cohere.Client(COHERE_API_KEY)

```

```txt title="Output"
Enter your Cohere API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·
```

## **Step 1: Loading a 10-K**

You may run the following cells to load a 10-K that has already been preprocessed with OCR.

> ðŸ’¡ If you'd like to run the OCR pipeline yourself, you can find more info in the section titled **PDF to Text using OCR and `pdf2image`**.

```python PYTHON
# Using langchain here since they have access to the Unstructured Data Loader powered by unstructured.io
from langchain_community.document_loaders import UnstructuredURLLoader

# Load up Airbnb's 10-K from this past fiscal year (filed in 2024)
# Feel free to fill in some other EDGAR path
url = "https://www.sec.gov/Archives/edgar/data/1559720/000155972024000006/abnb-20231231.htm"
loader = UnstructuredURLLoader(urls=[url], headers={"User-Agent": "cohere cohere@cohere.com"})
documents = loader.load()

edgar_10k = documents[0].page_content

# Load the document(s) as simple text nodes, to be passed to the tokenization processor
nodes = [TextNode(text=document.page_content, id_=f"doc_{i}") for i, document in enumerate(documents)]
```

```txt title="Output"
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /root/nltk_data...
[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.
```

We'll need to convert the text into chunks of a certain size in order for the Cohere embedding model to properly ingest them down the line.

We choose to use LlamaIndex's `SentenceSplitter` in this case in order to get these chunks. We must pass a tokenization callable, which we can do using the `transformers` library.

You may also apply further transformations from the LlamaIndex repo if you so choose. Take a look at the [docs](https://docs.llamaindex.ai/en/stable/understanding/loading/loading.html) for inspiration on what is possible with transformations.

```python PYTHON
from llama_index.core.ingestion import IngestionPipeline
from llama_index.core.node_parser import SentenceSplitter

from transformers import AutoTokenizer

model_id = "CohereForAI/c4ai-command-r-v01"
tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)

# TODO: replace with a HF implementation so this is much faster. We'll
# presumably release it when we OS the model
tokenizer_fn = lambda x: tokenizer(x).input_ids if len(x) > 0 else []

pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=512, chunk_overlap=0, tokenizer=tokenizer_fn)
    ]
)

# Run the pipeline to transform the text
nodes = pipeline.run(nodes=nodes)
```

```txt title="Output"
/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning:
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
    warnings.warn(



tokenizer_config.json:   0%|          | 0.00/7.92k [00:00<?, ?B/s]



tokenization_cohere_fast.py:   0%|          | 0.00/43.7k [00:00<?, ?B/s]



configuration_cohere.py:   0%|          | 0.00/7.37k [00:00<?, ?B/s]


A new version of the following files was downloaded from https://huggingface.co/CohereForAI/c4ai-command-r-v01:
- configuration_cohere.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/CohereForAI/c4ai-command-r-v01:
- tokenization_cohere_fast.py
- configuration_cohere.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.



tokenizer.json:   0%|          | 0.00/12.8M [00:00<?, ?B/s]



special_tokens_map.json:   0%|          | 0.00/429 [00:00<?, ?B/s]


Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
```

## **Step 2: Load document into a LlamaIndex vector store**

Loading the document into a LlamaIndex vector store will allow us to use the Cohere embedding model and rerank model to retrieve the relevant parts of the form to pass into Command.

```python PYTHON
from llama_index.core import Settings, VectorStoreIndex

from llama_index.postprocessor.cohere_rerank import CohereRerank

from llama_index.embeddings.cohere import CohereEmbedding

# Instantiate the embedding model
embed_model = CohereEmbedding(cohere_api_key=COHERE_API_KEY)

# Global settings
Settings.chunk_size = 512
Settings.embed_model = embed_model

# Create the vector store
index = VectorStoreIndex(nodes)

retriever = index.as_retriever(similarity_top_k=30) # Change to whatever top_k you want

# Instantiate the reranker
rerank = CohereRerank(api_key=COHERE_API_KEY, top_n=15)

# Function `retrieve` is ready, using both Cohere embeddings for similarity search as well as
retrieve = lambda query: rerank.postprocess_nodes(retriever.retrieve(query), query_str=query)
```

## **Step 3: Query generation and retrieval**

In order to do RAG, we need a query or a set of queries to actually *do* the retrieval step. As is standard in RAG settings, we'll use Command to generate those queries for us. Then, we'll use those queries along with the LlamaIndex retriever we built earlier to retrieve the most relevant pieces of the 10-K.

To learn more about document mode and query generation, check out [our documentation](https://docs.cohere.com/docs/retrieval-augmented-generation-rag).

```python PYTHON
PROMPT = "List the overall revenue numbers for 2021, 2022, and 2023 in the 10-K as bullet points, then explain the revenue growth trends."

# Get queries to run against our index from the model
r = co.chat(PROMPT, model="command-r", search_queries_only=True)
if r.search_queries:
    queries = [q["text"] for q in r.search_queries]
else:
    print("No queries returned by the model")
```

Now, with the queries in hand, we search against our vector index.

```python PYTHON
# Convenience function for formatting documents
def format_for_cohere_client(nodes_):
    return [
        {
            "text": node.node.text,
            "llamaindex_id": node.node.id_,
        }
        for node
        in nodes_
    ]


documents = []
# Retrieve a set of chunks from the vector index and append them to the list of
# documents that should be included in the final RAG step
for query in queries:
    ret_nodes = retrieve(query)
    documents.extend(format_for_cohere_client(ret_nodes))

# One final dedpulication step in case multiple queries return the same chunk
documents = [dict(t, id=f"doc_{i}") for i, t in enumerate({tuple(d.items()) for d in documents})]
```

## **Step 4: Make a RAG request to Command using document mode**

Now that we have our nicely formatted chunks from the 10-K, we can pass them directly into Command using the Cohere SDK. By passing the chunks into the `documents` kwarg, we enable document mode, which will perform grounded inference on the documents you pass in.

You can see this for yourself by inspecting the `response.citations` field to check where the model is citing from.

You can learn more about the `chat` endpoint by checking out the API reference [here](https://docs.cohere.com/reference/chat).

```python PYTHON
# Make a request to the model
response = co.chat(
    message=PROMPT,
    model="command-r",
    temperature=0.3,
    documents=documents,
    prompt_truncation="AUTO"
)

print(response.text)
```

```txt title="Output"
Here are the overall revenue numbers for the years 2021, 2022, and 2023 as bullet points:
- 2021: $5,992 million
- 2022: $8,399 million
- 2023: $9,917 million

Revenue increased by 18% in 2023 compared to 2022, primarily due to a 14% increase in Nights and Experiences Booked, which reached 54.5 million. This, combined with higher average daily rates, resulted in a 16% increase in Gross Booking Value, which reached $10.0 billion.

The revenue growth trend demonstrates sustained strong travel demand. On a constant-currency basis, revenue increased by 17% in 2023 compared to the previous year.

Other factors influencing the company's financial performance are described outside of the revenue growth trends.
```

```python PYTHON
# Helper function for displaying response WITH citations
def insert_citations(text: str, citations: list[dict]):
    """
    A helper function to pretty print citations.
    """
    offset = 0
    # Process citations in the order they were provided
    for citation in citations:
        # Adjust start/end with offset
        start, end = citation['start'] + offset, citation['end'] + offset
        cited_docs = [doc[4:] for doc in citation["document_ids"]]
        # Shorten citations if they're too long for convenience
        if len(cited_docs) > 3:
            placeholder = "[" + ", ".join(cited_docs[:3]) + "...]"
        else:
            placeholder = "[" + ", ".join(cited_docs) + "]"
        # ^ doc[4:] removes the 'doc_' prefix, and leaves the quoted document
        modification = f'{text[start:end]} {placeholder}'
        # Replace the cited text with its bolded version + placeholder
        text = text[:start] + modification + text[end:]
        # Update the offset for subsequent replacements
        offset += len(modification) - (end - start)

    return text

print(insert_citations(response.text, response.citations))
```

```txt title="Output"
Here are the overall revenue numbers for the years 2021, 2022, and 2023 as bullet points:
- 2021: $5,992 million [13]
- 2022: $8,399 million [13]
- 2023: $9,917 million [13]

Revenue increased by 18% in 2023 [11] compared to 2022, primarily due to a 14% increase in Nights and Experiences Booked [11], which reached 54.5 million. [11] This, combined with higher average daily rates [11], resulted in a 16% increase in Gross Booking Value [11], which reached $10.0 billion. [11]

The revenue growth trend demonstrates sustained strong travel demand. [11] On a constant-currency basis [11], revenue increased by 17% in 2023 [11] compared to the previous year.

Other factors [8, 14] influencing the company's financial performance are described outside of the revenue growth trends. [8, 14]
```

# **Appendix**

## PDF to Text using OCR and `pdf2image`

This method will be required for any PDFs you have that need to be converted to text.

**WARNING**: this process can take a long time without the proper optimizations. We have provided a snippet for your use below, but use at your own risk.

To go from PDF to text with PyTesseract, there is an intermediary step of converting the PDF to an image first, then passing that image into the OCR package, as OCR is usually only available for images.

To do this, we use `pdf2image`, which uses `poppler` behind the scenes to convert the PDF into a PNG. From there, we can pass the image (which is a PIL Image object) directly into the OCR tool.

```python PYTHON
import pytesseract
from pdf2image import convert_from_path

# pdf2image extracts as a list of PIL.Image objects
# TODO: host this PDF somewhere
pages = convert_from_path("/content/uber_10k.pdf")

# We access the only page in this sample PDF by indexing at 0
pages = [pytesseract.image_to_string(page) for page in pages]
```

## Token count / price comparison and latency

```python PYTHON
def get_response(prompt, rag):
    if rag:
        # Get queries to run against our index from the model
        r = co.chat(prompt, model="command-r", search_queries_only=True)
        if r.search_queries:
            queries = [q["text"] for q in r.search_queries]
        else:
            print("No queries returned by the model")

        documents = []
        # Retrieve a set of chunks from the vector index and append them to the list of
        # documents that should be included in the final RAG step
        for query in queries:
            ret_nodes = retrieve(query)
            documents.extend(format_for_cohere_client(ret_nodes))

        # One final dedpulication step in case multiple queries return the same chunk
        documents = [dict(t) for t in {tuple(d.items()) for d in documents}]

        # Make a request to the model
        response = co.chat(
            message=prompt,
            model="command-r",
            temperature=0.3,
            documents=documents,
            prompt_truncation="AUTO"
        )
    else:
        response = co.chat(
            message=prompt,
            model="command-r",
            temperature=0.3,
        )

    return response
```

```python PYTHON
prompt_template = """# financial form 10-K
{tenk}

# question
{question}"""

full_context_prompt = prompt_template.format(tenk=edgar_10k, question=PROMPT)
```

```python PYTHON
r1 = get_response(PROMPT, rag=True)
r2 = get_response(full_context_prompt, rag=False)
```

```python PYTHON
def get_price(r):
    return (r.token_count["prompt_tokens"] * 0.5 / 10e6) + (r.token_count["response_tokens"] * 1.5 / 10e6)
```

```python PYTHON
rag_price = get_price(r1)
full_context_price = get_price(r2)

print(f"RAG is {(full_context_price - rag_price) / full_context_price:.0%} cheaper than full context")
```

```txt title="Output"
RAG is 93% cheaper than full context
```

```python PYTHON
%timeit get_response(PROMPT, rag=True)
```

```txt title="Output"
14.9 s Â± 1.4 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```

```python PYTHON
%timeit get_response(full_context_prompt, rag=False)
```

```txt title="Output"
22.7 s Â± 7.43 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)
```


# Analyzing Hacker News with Cohere

> This page describes building a generative-AI powered tool to analyze headlines with Cohere.

<CookbookHeader href="https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Analyzing_Hacker_News_with_Six_Language_Understanding_Methods.ipynb" />

Large language models give machines a vastly improved representation and understanding of language. These abilities give developers more options for content recommendation, analysis, and filtering.

In this notebook we take thousands of the most popular posts from Hacker News and demonstrate some of these functionalities:

1. Given an existing post title, retrieve the most similar posts (nearest neighbor search using embeddings)
2. Given a query that we write, retrieve the most similar posts
3. Plot the archive of articles by similarity (where similar posts are close together and different ones are far)
4. Cluster the posts to identify the major common themes
5. Extract major keywords from each cluster so we can identify what the clsuter is about
6. (Experimental) Name clusters with a generative language model

## Setup

Let's start by installing the tools we'll need and then importing them.

```python PYTHON
!pip install cohere umap-learn altair annoy bertopic
```

```
Requirement already satisfied: cohere in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (5.1.5)
Requirement already satisfied: umap-learn in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (0.5.5)
Requirement already satisfied: altair in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (5.2.0)
Requirement already satisfied: annoy in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (1.17.3)
Requirement already satisfied: bertopic in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (0.16.0)
Requirement already satisfied: httpx>=0.21.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (0.27.0)
Requirement already satisfied: pydantic>=1.9.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (2.6.0)
Requirement already satisfied: typing_extensions>=4.0.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from cohere) (4.10.0)
Requirement already satisfied: numpy>=1.17 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.24.3)
Requirement already satisfied: scipy>=1.3.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.11.1)
Requirement already satisfied: scikit-learn>=0.22 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.3.0)
Requirement already satisfied: numba>=0.51.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.57.0)
Requirement already satisfied: pynndescent>=0.5 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.5.12)
Requirement already satisfied: tqdm in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from umap-learn) (4.65.0)
Requirement already satisfied: jinja2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (3.1.2)
Requirement already satisfied: jsonschema>=3.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (4.17.3)
Requirement already satisfied: packaging in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (23.2)
Requirement already satisfied: pandas>=0.25 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (2.0.3)
Requirement already satisfied: toolz in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from altair) (0.12.0)
Requirement already satisfied: hdbscan>=0.8.29 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (0.8.33)
Requirement already satisfied: sentence-transformers>=0.4.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (2.6.1)
Requirement already satisfied: plotly>=4.7.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from bertopic) (5.9.0)
Requirement already satisfied: cython<3,>=0.27 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)
Requirement already satisfied: joblib>=1.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (1.2.0)
Requirement already satisfied: anyio in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (3.5.0)
Requirement already satisfied: certifi in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (2023.11.17)
Requirement already satisfied: httpcore==1.* in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (1.0.2)
Requirement already satisfied: idna in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (3.4)
Requirement already satisfied: sniffio in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpx>=0.21.2->cohere) (1.2.0)
Requirement already satisfied: h11<0.15,>=0.13 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)
Requirement already satisfied: attrs>=17.4.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair) (22.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair) (0.18.0)
Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.40.0)
Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2023.3.post1)
Requirement already satisfied: tzdata>=2022.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->altair) (2023.3)
Requirement already satisfied: tenacity>=6.2.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)
Requirement already satisfied: annotated-types>=0.4.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (0.6.0)
Requirement already satisfied: pydantic-core==2.16.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from pydantic>=1.9.2->cohere) (2.16.1)
Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)
Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.39.3)
Requirement already satisfied: torch>=1.11.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.2.2)
Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.22.2)
Requirement already satisfied: Pillow in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (10.0.1)
Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from jinja2->altair) (2.1.1)
Requirement already satisfied: filelock in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.9.0)
Requirement already satisfied: fsspec>=2023.5.0 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.3.1)
Requirement already satisfied: pyyaml>=5.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0)
Requirement already satisfied: requests in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)
Requirement already satisfied: six>=1.5 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25->altair) (1.16.0)
Requirement already satisfied: sympy in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.11.1)
Requirement already satisfied: networkx in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1)
Requirement already satisfied: regex!=2019.12.17 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2022.7.9)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)
Requirement already satisfied: safetensors>=0.4.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)
Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.18)
Requirement already satisfied: mpmath>=0.19 in /Users/alexiscook/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)
```

```python PYTHON
import cohere
import numpy as np
import pandas as pd
import umap
import altair as alt
from annoy import AnnoyIndex
import warnings
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import CountVectorizer
from bertopic.vectorizers import ClassTfidfTransformer

warnings.filterwarnings('ignore')
pd.set_option('display.max_colwidth', None)
```

Fill in your Cohere API key in the next cell. To do this, begin by [signing up to Cohere](https://dashboard.cohere.com/) (for free!) if you haven't yet. Then get your API key [here](https://dashboard.cohere.com/api-keys).

```python PYTHON
co = cohere.Client("COHERE_API_KEY") # Insert your Cohere API key
```

## Dataset: Top 3,000 Ask HN posts

We will use the top 3,000 posts from the Ask HN section of Hacker News. We provide a CSV containing the posts.

```python PYTHON
df = pd.read_csv('https://storage.googleapis.com/cohere-assets/blog/text-clustering/data/askhn3k_df.csv', index_col=0)

print(f'Loaded a DataFrame with {len(df)} rows')
```

```
Loaded a DataFrame with 3000 rows
```

```python PYTHON
df.head()
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          title
        </th>

        <th>
          url
        </th>

        <th>
          text
        </th>

        <th>
          dead
        </th>

        <th>
          by
        </th>

        <th>
          score
        </th>

        <th>
          time
        </th>

        <th>
          timestamp
        </th>

        <th>
          type
        </th>

        <th>
          id
        </th>

        <th>
          parent
        </th>

        <th>
          descendants
        </th>

        <th>
          ranking
        </th>

        <th>
          deleted
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          0
        </th>

        <td>
          I'm a software engineer going blind, how should I prepare?
        </td>

        <td>
          NaN
        </td>

        <td>
          I&#x27;m a 24 y&#x2F;o full stack engineer (I know some of you are rolling your eyes right now, just highlighting that I have experience on frontend apps as well as backend architecture). I&#x27;ve been working professionally for ~7 years building mostly javascript projects but also some PHP. Two years ago I was diagnosed with a condition called &quot;Usher&#x27;s Syndrome&quot; - characterized by hearing loss, balance issues, and progressive vision loss.<p>I know there are blind software engineers out there. My main questions are:<p>- Are there blind frontend engineers?<p>- What kinds of software engineering lend themselves to someone with limited vision? Backend only?<p>- Besides a screen reader, what are some of the best tools for building software with limited vision?<p>- Does your company employ blind engineers? How well does it work? What kind of engineer are they?<p>I&#x27;m really trying to get ahead of this thing and prepare myself as my vision is degrading rather quickly. I&#x27;m not sure what I can do if I can&#x27;t do SE as I don&#x27;t have any formal education in anything. I&#x27;ve worked really hard to get to where I am and don&#x27;t want it to go to waste.<p>Thank you for any input, and stay safe out there!<p>Edit:<p>Thank you all for your links, suggestions, and moral support, I really appreciate it. Since my diagnosis I&#x27;ve slowly developed a crippling anxiety centered around a feeling that I need to figure out the rest of my life before it&#x27;s too late. I know I shouldn&#x27;t think this way but it is hard not to. I&#x27;m very independent and I feel a pressure to &quot;show up.&quot; I will look into these opportunities mentioned and try to get in touch with some more members of the blind engineering community.
        </td>

        <td>
          NaN
        </td>

        <td>
          zachrip
        </td>

        <td>
          3270
        </td>

        <td>
          1587332026
        </td>

        <td>
          2020-04-19 21:33:46+00:00
        </td>

        <td>
          story
        </td>

        <td>
          22918980
        </td>

        <td>
          NaN
        </td>

        <td>
          473.0
        </td>

        <td>
          NaN
        </td>

        <td>
          NaN
        </td>
      </tr>

      <tr>
        <th>
          1
        </th>

        <td>
          Am I the longest-serving programmer â€“ 57 years and counting?
        </td>

        <td>
          NaN
        </td>

        <td>
          In May of 1963, I started my first full-time job as a computer programmer for Mitchell Engineering Company, a supplier of steel buildings.  At Mitchell, I developed programs in Fortran II on an IBM 1620 mostly to improve the efficiency of order processing and fulfillment.  Since then, all my jobs for the past 57 years have involved computer programming.  I am now a data scientist developing cloud-based big data fraud detection algorithms using machine learning and other advanced analytical technologies.  Along the way, I earned a Masterâ€™s in Operations Research and a Masterâ€™s in Management Science, studied artificial intelligence for 3 years in a Ph.D. program for engineering, and just two years ago I received Graduate Certificates in Big Data Analytics from the schools of business and computer science at a local university (FAU).  In addition, I currently hold the designation of Certified Analytics Professional (CAP).  At 74, I still have no plans to retire or to stop programming.
        </td>

        <td>
          NaN
        </td>

        <td>
          genedangelo
        </td>

        <td>
          2634
        </td>

        <td>
          1590890024
        </td>

        <td>
          2020-05-31 01:53:44+00:00
        </td>

        <td>
          story
        </td>

        <td>
          23366546
        </td>

        <td>
          NaN
        </td>

        <td>
          531.0
        </td>

        <td>
          NaN
        </td>

        <td>
          NaN
        </td>
      </tr>

      <tr>
        <th>
          2
        </th>

        <td>
          Is S3 down?
        </td>

        <td>
          NaN
        </td>

        <td>
          I&#x27;m getting<p>{\n  &quot;errorCode&quot; : &quot;InternalError&quot;\n}<p>When I attempt to use the AWS Console to view s3
        </td>

        <td>
          NaN
        </td>

        <td>
          iamdeedubs
        </td>

        <td>
          2589
        </td>

        <td>
          1488303958
        </td>

        <td>
          2017-02-28 17:45:58+00:00
        </td>

        <td>
          story
        </td>

        <td>
          13755673
        </td>

        <td>
          NaN
        </td>

        <td>
          1055.0
        </td>

        <td>
          NaN
        </td>

        <td>
          NaN
        </td>
      </tr>

      <tr>
        <th>
          3
        </th>

        <td>
          What tech job would let me get away with the least real work possible?
        </td>

        <td>
          NaN
        </td>

        <td>
          Hey HN,<p>I&#x27;ll probably get a lot of flak for this. Sorry.<p>I&#x27;m an average developer looking for ways to work as little as humanely possible.<p>The pandemic made me realize that I do not care about working anymore. The software I build is useless. Time flies real fast and I have to focus on my passions (which are not monetizable).<p>Unfortunately, I require shelter, calories and hobby materials. Thus the need for some kind of job.<p>Which leads me to ask my fellow tech workers, what kind of job (if any) do you think would fit the following requirements :<p>- No &#x2F; very little involvement in the product itself (I do not care.)<p>- Fully remote (You can&#x27;t do much when stuck in the office. Ideally being done in 2 hours in the morning then chilling would be perfect.)<p>- Low expectactions &#x2F; vague job description.<p>- Salary can be on the lower side.<p>- No career advancement possibilities required. Only tech, I do not want to manage people.<p>- Can be about helping other developers, setting up infrastructure&#x2F;deploy or pure data management since this is fun.<p>I think the only possible jobs would be some kind of backend-only dev or devops&#x2F;sysadmin work. But I&#x27;m not sure these exist anymore, it seems like you always end up having to think about the product itself. Web dev jobs always required some involvement in the frontend.<p>Thanks for any advice (or hate, which I can&#x27;t really blame you for).
        </td>

        <td>
          NaN
        </td>

        <td>
          lmueongoqx
        </td>

        <td>
          2022
        </td>

        <td>
          1617784863
        </td>

        <td>
          2021-04-07 08:41:03+00:00
        </td>

        <td>
          story
        </td>

        <td>
          26721951
        </td>

        <td>
          NaN
        </td>

        <td>
          1091.0
        </td>

        <td>
          NaN
        </td>

        <td>
          NaN
        </td>
      </tr>

      <tr>
        <th>
          4
        </th>

        <td>
          What books changed the way you think about almost everything?
        </td>

        <td>
          NaN
        </td>

        <td>
          I was reflecting today about how often I think about Freakonomics. I don&#x27;t study it religiously. I read it one time more than 10 years ago. I can only remember maybe a single specific anecdote from the book. And yet the simple idea that basically every action humans take can be traced back to an incentive has fundamentally changed the way I view the world. Can anyone recommend books that have had a similar impact on them?
        </td>

        <td>
          NaN
        </td>

        <td>
          anderspitman
        </td>

        <td>
          2009
        </td>

        <td>
          1549387905
        </td>

        <td>
          2019-02-05 17:31:45+00:00
        </td>

        <td>
          story
        </td>

        <td>
          19087418
        </td>

        <td>
          NaN
        </td>

        <td>
          1165.0
        </td>

        <td>
          NaN
        </td>

        <td>
          NaN
        </td>
      </tr>
    </tbody>
  </table>
</div>

We calculate the embeddings using Cohere's `embed-v4.0` model. The resulting embeddings matrix has 3,000 rows (one for each post) and 1024 columns (meaning each post title is represented with a 1024-dimensional embedding).

```python PYTHON
batch_size = 90

embeds_list = []
for i in range(0, len(df), batch_size):
    batch = df[i : min(i + batch_size, len(df))]
    texts = list(batch["title"])
    embs_batch = co.embed(
        texts=texts, model="embed-v4.0", input_type="search_document"
    ).embeddings
    embeds_list.extend(embs_batch)

embeds = np.array(embeds_list)
embeds.shape
```

```
(3000, 1024)
```

## Building a semantic search index

For nearest-neighbor search, we can use the open-source Annoy library. Let's create a semantic search index and feed it all the embeddings.

```python PYTHON
search_index = AnnoyIndex(embeds.shape[1], 'angular')
for i in range(len(embeds)):
    search_index.add_item(i, embeds[i])

search_index.build(10) # 10 trees
search_index.save('askhn.ann')
```

```
True
```

## 1- Given an existing post title, retrieve the most similar posts (nearest neighbor search using embeddings)

We can query neighbors of a specific post using `get_nns_by_item`.

```python PYTHON
example_id = 50

similar_item_ids = search_index.get_nns_by_item(example_id,
                                                10, # Number of results to retrieve
                                                include_distances=True)
results = pd.DataFrame(data={'post titles': df.iloc[similar_item_ids[0]]['title'],
                             'distance': similar_item_ids[1]}).drop(example_id)

print(f"Query post:'{df.iloc[example_id]['title']}'\nNearest neighbors:")
results
```

```
Query post:'Pick startups for YC to fund'
Nearest neighbors:
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          post titles
        </th>

        <th>
          distance
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          2991
        </th>

        <td>
          Best Bank for Startups?
        </td>

        <td>
          0.883494
        </td>
      </tr>

      <tr>
        <th>
          2910
        </th>

        <td>
          Who's looking for a cofounder?
        </td>

        <td>
          0.885087
        </td>
      </tr>

      <tr>
        <th>
          31
        </th>

        <td>
          What startup/technology is on your 'to watch' list?
        </td>

        <td>
          0.887212
        </td>
      </tr>

      <tr>
        <th>
          685
        </th>

        <td>
          What startup/technology is on your 'to watch' list?
        </td>

        <td>
          0.887212
        </td>
      </tr>

      <tr>
        <th>
          2123
        </th>

        <td>
          Who is seeking a cofounder?
        </td>

        <td>
          0.889451
        </td>
      </tr>

      <tr>
        <th>
          727
        </th>

        <td>
          Agriculture startups doing interesting work?
        </td>

        <td>
          0.899192
        </td>
      </tr>

      <tr>
        <th>
          2972
        </th>

        <td>
          How should I evaluate a startup as I job hunt?
        </td>

        <td>
          0.901621
        </td>
      </tr>

      <tr>
        <th>
          2589
        </th>

        <td>
          What methods do you use to gain early customers for your startup?
        </td>

        <td>
          0.903065
        </td>
      </tr>

      <tr>
        <th>
          2708
        </th>

        <td>
          Is there VC appetite for defense related startups?
        </td>

        <td>
          0.904016
        </td>
      </tr>
    </tbody>
  </table>
</div>

## 2- Given a query that we write, retrieve the most similar posts

We're not limited to searching using existing items. If we get a query, we can embed it and find its nearest neighbors from the dataset.

```python PYTHON
query = "How can I improve my knowledge of calculus?"

query_embed = co.embed(texts=[query],
                       model="embed-v4.0",
                       truncate="RIGHT",
                       input_type="search_query").embeddings

similar_item_ids = search_index.get_nns_by_vector(query_embed[0], 10, include_distances=True)

results = pd.DataFrame(data={'texts': df.iloc[similar_item_ids[0]]['title'],
                             'distance': similar_item_ids[1]})
print(f"Query:'{query}'\nNearest neighbors:")
results
```

```
Query:'How can I improve my knowledge of calculus?'
Nearest neighbors:
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          texts
        </th>

        <th>
          distance
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          2457
        </th>

        <td>
          How do I improve my command of mathematical language?
        </td>

        <td>
          0.931286
        </td>
      </tr>

      <tr>
        <th>
          1235
        </th>

        <td>
          How to learn new things better?
        </td>

        <td>
          1.024635
        </td>
      </tr>

      <tr>
        <th>
          145
        </th>

        <td>
          How to self-learn math?
        </td>

        <td>
          1.044135
        </td>
      </tr>

      <tr>
        <th>
          1317
        </th>

        <td>
          How can I learn to read mathematical notation?
        </td>

        <td>
          1.050976
        </td>
      </tr>

      <tr>
        <th>
          910
        </th>

        <td>
          How Do You Learn?
        </td>

        <td>
          1.061253
        </td>
      </tr>

      <tr>
        <th>
          2432
        </th>

        <td>
          How did you learn math notation?
        </td>

        <td>
          1.070800
        </td>
      </tr>

      <tr>
        <th>
          1994
        </th>

        <td>
          How do I become smarter?
        </td>

        <td>
          1.083434
        </td>
      </tr>

      <tr>
        <th>
          1529
        </th>

        <td>
          How do you personally learn?
        </td>

        <td>
          1.086088
        </td>
      </tr>

      <tr>
        <th>
          796
        </th>

        <td>
          How do you keep improving?
        </td>

        <td>
          1.087251
        </td>
      </tr>

      <tr>
        <th>
          1286
        </th>

        <td>
          How do I learn drawing?
        </td>

        <td>
          1.088468
        </td>
      </tr>
    </tbody>
  </table>
</div>

## 3- Plot the archive of articles by similarity

What if we want to browse the archive instead of only searching it? Let's plot all the questions in a 2D chart so you're able to visualize the posts in the archive and their similarities.

```python PYTHON
reducer = umap.UMAP(n_neighbors=100)
umap_embeds = reducer.fit_transform(embeds)
```

```python PYTHON
df['x'] = umap_embeds[:,0]
df['y'] = umap_embeds[:,1]

chart = alt.Chart(df).mark_circle(size=60).encode(
    x=#'x',
    alt.X('x',
        scale=alt.Scale(zero=False),
        axis=alt.Axis(labels=False, ticks=False, domain=False)
    ),
    y=
    alt.Y('y',
        scale=alt.Scale(zero=False),
        axis=alt.Axis(labels=False, ticks=False, domain=False)
    ),
    tooltip=['title']
    ).configure(background="#FDF7F0"
    ).properties(
        width=700,
        height=400,
        title='Ask HN: top 3,000 posts'
        )

chart.interactive()
```

## 4- Cluster the posts to identify the major common themes

Let's proceed to cluster the embeddings using KMeans from scikit-learn.

```python PYTHON
n_clusters = 8

kmeans_model = KMeans(n_clusters=n_clusters, random_state=0)
classes = kmeans_model.fit_predict(embeds)
```

## 5- Extract major keywords from each cluster so we can identify what the cluster is about

```python PYTHON
documents =  df['title']
documents = pd.DataFrame({"Document": documents,
                          "ID": range(len(documents)),
                          "Topic": None})
documents['Topic'] = classes
documents_per_topic = documents.groupby(['Topic'], as_index=False).agg({'Document': ' '.join})
count_vectorizer = CountVectorizer(stop_words="english").fit(documents_per_topic.Document)
count = count_vectorizer.transform(documents_per_topic.Document)
words = count_vectorizer.get_feature_names_out()
```

```python PYTHON
ctfidf = ClassTfidfTransformer().fit_transform(count).toarray()
words_per_class = {label: [words[index] for index in ctfidf[label].argsort()[-10:]] for label in documents_per_topic.Topic}
df['cluster'] = classes
df['keywords'] = df['cluster'].map(lambda topic_num: ", ".join(np.array(words_per_class[topic_num])[:]))
```

## Plot with clusters and keywords information

We can now plot the documents with their clusters and keywords

```python PYTHON
selection = alt.selection_multi(fields=['keywords'], bind='legend')

chart = alt.Chart(df).transform_calculate(
    url='https://news.ycombinator.com/item?id=' + alt.datum.id
).mark_circle(size=60, stroke='#666', strokeWidth=1, opacity=0.3).encode(
    x=#'x',
    alt.X('x',
        scale=alt.Scale(zero=False),
        axis=alt.Axis(labels=False, ticks=False, domain=False)
    ),
    y=
    alt.Y('y',
        scale=alt.Scale(zero=False),
        axis=alt.Axis(labels=False, ticks=False, domain=False)
    ),
    href='url:N',
    color=alt.Color('keywords:N',
                    legend=alt.Legend(columns=1, symbolLimit=0, labelFontSize=14)
                   ),
    opacity=alt.condition(selection, alt.value(1), alt.value(0.2)),
    tooltip=['title', 'keywords', 'cluster', 'score', 'descendants']
).properties(
    width=800,
    height=500
).add_selection(
    selection
).configure_legend(labelLimit= 0).configure_view(
    strokeWidth=0
).configure(background="#FDF7F0").properties(
    title='Ask HN: Top 3,000 Posts'
)
chart.interactive()
```

## 6- (Experimental) Naming clusters with a generative language model

While the extracted keywords do add a lot of information to help us identify the clusters at a glance, we should be able to have a generative model look at these keywords and suggest a name. So far I have reasonable results from a prompt that looks like this:

```
The common theme of the following words: books, book, read, the, you, are, what, best, in, your
is that they all relate to favorite books to read.
---
The common theme of the following words: startup, company, yc, failed
is that they all relate to startup companies and their failures.
---
The common theme of the following words: freelancer, wants, hired, be, who, seeking, to, 2014, 2020, april
is that they all relate to hiring for a freelancer to join the team of a startup.
---
The common theme of the following words: <insert keywords here>
is that they all relate to
```

There's a lot of room for improvement though. I'm really excited by this use case because it adds so much information. Imagine if the in the following tree of topics, you assigned each cluster an intelligible name. Then imagine if you assigned each *branching* a name as well

<img alt="" src="https://raw.githubusercontent.com/cohere-ai/cohere-developer-experience/main/notebooks/images/kmeans-centroid-dendrogram.png" />

We canâ€™t wait to see what you start building! Share your projects or find support on our [Discord server](https://discord.com/invite/co-mmunity).


# Article Recommender via Embedding & Classification

> This page describes how to build a generative-AI tool to recommend articles with Cohere.

<CookbookHeader href="https://github.com/cohere-ai/cohere-developer-experience/blob/main/notebooks/guides/Article_Recommender_with_Text_Embedding_Classification_Extraction.ipynb" />

## Article Recommender with Text Embedding, Classification, and Extraction

This is a simple demonstration of how we can stack multiple NLP models together\
to get an output much closer to our desired outcome.

Embeddings can capture the meaning of a piece of text beyond keyword-matching. In this article, we will build a simple news article recommender system that computes the embeddings of all available articles and recommend the most relevant articles based on embeddings similarity.

We will also make the recommendation tighter by using text classification to recommend only articles within the same category. We will then extract a list of tags from each recommended article, which can further help readers discover new articles.

All this will be done via three Cohere API endpoints stacked together: Embed, Classify, and Chat.

<img alt="Article recommender with Embed, Classify, and Chat" src="https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-1.png" />

We will implement the following steps:

**1: Find the most similar articles to the one currently reading using embeddings.**

**2: Keep only articles of the same category using text classification.**

**3: Extract tags from these articles.**

**4: Show the top 5 recommended articles.**

```python PYTHON
! pip install cohere
```

```txt title="Output"
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting cohere
  Downloading cohere-1.3.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)
[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18.0 MB 135 kB/s
[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cohere) (2.23.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (1.24.3)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2022.6.15)
Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2.10)
Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (3.0.4)
Installing collected packages: cohere
Successfully installed cohere-1.3.10
```

```python PYTHON
import numpy as np
import pandas as pd
import re
import cohere

co = cohere.Client("COHERE_API_KEY") # Get your API key: https://dashboard.cohere.com/api-keys

```

<img alt="Step 1 - Embed" src="https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-2.png" />

## 1.1: Get articles

Throughout this article, we'll use the [BBC news article dataset](https://www.kaggle.com/competitions/learn-ai-bbc/data?select=BBC+News+Train.csv) as an example [\[Source\]](http://mlg.ucd.ie/datasets/bbc.html). This dataset consists of articles from a few categories: business, politics, tech, entertainment, and sport.

We'll extract a subset of the data and in Step 1, use the first 100 data points.

```python PYTHON
df = pd.read_csv('https://raw.githubusercontent.com/cohere-ai/cohere-developer-experience/main/notebooks/data/bbc_news_subset.csv', delimiter=',')

INP_START = 0
INP_END = 100
df_inputs = df.iloc[INP_START:INP_END]
df_inputs = df_inputs.copy()

df_inputs.drop(['ArticleId','Category'],axis=1,inplace=True)

df_inputs.head()
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          Text
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          0
        </th>

        <td>
          worldcom ex-boss launches defence lawyers defe...
        </td>
      </tr>

      <tr>
        <th>
          1
        </th>

        <td>
          german business confidence slides german busin...
        </td>
      </tr>

      <tr>
        <th>
          2
        </th>

        <td>
          bbc poll indicates economic gloom citizens in ...
        </td>
      </tr>

      <tr>
        <th>
          3
        </th>

        <td>
          lifestyle governs mobile choice faster bett...
        </td>
      </tr>

      <tr>
        <th>
          4
        </th>

        <td>
          enron bosses in $168m payout eighteen former e...
        </td>
      </tr>
    </tbody>
  </table>
</div>

## 1.2: Turn articles into embeddings

Next we turn each article text into embeddings. An [embedding](https://docs.cohere.ai/embedding-wiki) is a list of numbers that our models use to represent a piece of text, capturing its context and meaning.

We do this by calling Cohere's [Embed endpoint](https://docs.cohere.ai/embed-reference), which takes in text as input and returns embeddings as output.

```python PYTHON
articles = df_inputs['Text'].tolist()

output = co.embed(
            model ='embed-v4.0',
            input_type='search_document',
            texts = articles)
embeds = output.embeddings

print('Number of articles:', len(embeds))
```

```
Number of articles: 100
```

## 1.3: Pick one article and find the most similar articles

Next, we pick any one article to be the one the reader is currently reading (let's call this the target) and find other articles with the most similar embeddings (let's call these candidates) using cosine similarity.

[Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is a metric that measures how similar sequences of numbers are (embeddings in our case), and we compute it for each target-candidate pair.

```python PYTHON
print(f'Choose one article ID between {INP_START} and {INP_END-1} below...')
```

```
Choose one article ID between 0 and 99 below...
```

```python PYTHON
READING_IDX = 70

reading = embeds[READING_IDX]
```

```python PYTHON

from sklearn.metrics.pairwise import cosine_similarity

def get_similarity(target,candidates):
  # Turn list into array
  candidates = np.array(candidates)
  target = np.expand_dims(np.array(target),axis=0)

  # Calculate cosine similarity
  similarity_scores = cosine_similarity(target,candidates)
  similarity_scores = np.squeeze(similarity_scores).tolist()

  # Sort by descending order in similarity
  similarity_scores = list(enumerate(similarity_scores))
  similarity_scores = sorted(similarity_scores, key=lambda x:x[1], reverse=True)

  # Return similarity scores
  return similarity_scores
```

```python PYTHON
similarity = get_similarity(reading,embeds)

print('Target:')
print(f'[ID {READING_IDX}]',df_inputs['Text'][READING_IDX][:100],'...','\n')

print('Candidates:')
for i in similarity[1:6]: # Exclude the target article
  print(f'[ID {i[0]}]',df_inputs['Text'][i[0]][:100],'...')
```

```
Target:
[ID 70] aragones angered by racism fine spain coach luis aragones is furious after being fined by the spanis ...

Candidates:
[ID 23] ferguson urges henry punishment sir alex ferguson has called on the football association to punish a ...
[ID 51] mourinho defiant on chelsea form chelsea boss jose mourinho has insisted that sir alex ferguson and  ...
[ID 73] balco case trial date pushed back the trial date for the bay area laboratory cooperative (balco) ste ...
[ID 41] mcleish ready for criticism rangers manager alex mcleish accepts he is going to be criticised after  ...
[ID 42] premier league planning cole date the premier league is attempting to find a mutually convenient dat ...
```

<img alt="Step 2 - Classify" src="https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-3.png" />

Two articles may be similar but they may not necessarily belong to the same category. For example, an article about a sports team manager facing a fine may be similar to another about a business entity facing a fine, but they are not of the same category.

Perhaps we can make the system better by only recommending articles of the same category. For this, let's build a news category classifier.

## 2.1: Build a classifier

We use Cohere's [Classify endpoint](https://docs.cohere.com/reference/classify) to build a news category classifier, classifying articles into five categories: Business, Politics, Tech, Entertainment, and Sport.

A typical text classification model requires hundreds/thousands of data points to train, but with this endpoint, we can build a classifier with a few as five examples per class.

To build the classifier, we need a set of examples consisting of text (news text) and labels (news category). The BBC News dataset happens to have both (columns 'Text' and 'Category'), so this time weâ€™ll use the categories for building our examples. For this, we will set aside another portion of dataset.

```python PYTHON
EX_START = 100
EX_END = 200
df_examples = df.iloc[EX_START:EX_END]
df_examples = df_examples.copy()

df_examples.drop(['ArticleId'],axis=1,inplace=True)

df_examples.head()
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          Text
        </th>

        <th>
          Category
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          100
        </th>

        <td>
          honda wins china copyright ruling japan s hond...
        </td>

        <td>
          business
        </td>
      </tr>

      <tr>
        <th>
          101
        </th>

        <td>
          ukip could sue veritas defectors the uk indepe...
        </td>

        <td>
          politics
        </td>
      </tr>

      <tr>
        <th>
          102
        </th>

        <td>
          security warning over fbi virus the us feder...
        </td>

        <td>
          tech
        </td>
      </tr>

      <tr>
        <th>
          103
        </th>

        <td>
          europe backs digital tv lifestyle how people r...
        </td>

        <td>
          tech
        </td>
      </tr>

      <tr>
        <th>
          104
        </th>

        <td>
          celebrities get to stay in jungle all four con...
        </td>

        <td>
          entertainment
        </td>
      </tr>
    </tbody>
  </table>
</div>

With the Classify endpoint, there is a limit of 512 tokens per input. This means full articles won't be able to fit in the examples, so we will approximate and limit each article to its first 300 characters.

```python PYTHON
MAX_CHARS = 300

def shorten_text(text):
  return text[:MAX_CHARS]

df_examples['Text'] = df_examples['Text'].apply(shorten_text)
```

The Classify endpoint needs a minimum of 2 examples for each category. We'll have 5 examples each, sampled randomly from the dataset. We have 5 categories, so we will have a total of 25 examples.

```python PYTHON
EX_PER_CAT = 5

categories = df_examples['Category'].unique().tolist()

ex_texts = []
ex_labels = []
for category in categories:
  df_category = df_examples[df_examples['Category'] == category]
  samples = df_category.sample(n=EX_PER_CAT, random_state=42)
  ex_texts += samples['Text'].tolist()
  ex_labels += samples['Category'].tolist()

print(f'Number of examples per category: {EX_PER_CAT}')
print(f'List of categories: {categories}')
print(f'Number of categories: {len(categories)}')
print(f'Total number of examples: {len(ex_texts)}')
```

```
Number of examples per category: 5
List of categories: ['business', 'politics', 'tech', 'entertainment', 'sport']
Number of categories: 5
Total number of examples: 25
```

Once the examples are ready, we can now get the classifications. Here is a function that returns the classification given an input.

```python PYTHON

from cohere import ClassifyExample

examples = []
for txt, lbl in zip(ex_texts,ex_labels):
  examples.append(ClassifyExample(text=txt, label=lbl))

def classify_text(texts, examples):
    classifications = co.classify(
        inputs=texts,
        examples=examples
    )

    return [c.prediction for c in classifications.classifications]
```

## 2.2: Measure its performance

Before actually using the classifier, let's first test its performance. Here we take another 100 data points as the test dataset and the classifier will predict its class i.e. news category.

```python PYTHON
TEST_START = 200
TEST_END = 300
df_test = df.iloc[TEST_START:TEST_END]
df_test = df_test.copy()

df_test.drop(['ArticleId'],axis=1,inplace=True)

df_test['Text'] = df_test['Text'].apply(shorten_text)

df_test.head()
```

<div>
  <table border="1" class="dataframe fern-table">
    <thead>
      <tr>
        <th />

        <th>
          Text
        </th>

        <th>
          Category
        </th>
      </tr>
    </thead>

    <tbody>
      <tr>
        <th>
          200
        </th>

        <td>
          sa return to mauritius top seeds south africa ...
        </td>

        <td>
          sport
        </td>
      </tr>

      <tr>
        <th>
          201
        </th>

        <td>
          snow patrol feted at irish awards snow patrol ...
        </td>

        <td>
          entertainment
        </td>
      </tr>

      <tr>
        <th>
          202
        </th>

        <td>
          clyde 0-5 celtic celtic brushed aside clyde to...
        </td>

        <td>
          sport
        </td>
      </tr>

      <tr>
        <th>
          203
        </th>

        <td>
          bad weather hits nestle sales a combination of...
        </td>

        <td>
          business
        </td>
      </tr>

      <tr>
        <th>
          204
        </th>

        <td>
          net fingerprints combat attacks eighty large n...
        </td>

        <td>
          tech
        </td>
      </tr>
    </tbody>
  </table>
</div>

```python PYTHON
predictions = []
BATCH_SIZE = 90 # The API accepts a maximum of 96 inputs
for i in range(0, len(df_test['Text']), BATCH_SIZE):
    batch_texts = df_test['Text'][i:i+BATCH_SIZE].tolist()
    predictions.extend(classify_text(batch_texts, examples))

actual = df_test['Category'].tolist()
```

```python PYTHON
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(actual, predictions)
print(f'Accuracy: {accuracy*100}')
```

```
Accuracy: 89.0
```

We get a good accuracy score of 91%, so the classifier is ready to be
implemented in our recommender system.

<img alt="Step 3 - Extract" src="https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-4.png" />

We now proceed to the tags extraction step. Compared to the previous two steps, this step is not about sorting or filtering articles, but rather enriching them with more information.

We do this with the Chat endpoint.

We call the endpoint by specifying a few settings, and it will generate the corresponding extractions.

```python PYTHON
def extract_tags(article):
  prompt = f"""Given an article, extract a list of tags containing keywords of that article.

Article: japanese banking battle at an end japan s sumitomo mitsui \
financial has withdrawn its takeover offer for rival bank ufj holdings enabling the \
latter to merge with mitsubishi tokyo.  sumitomo bosses told counterparts at ufj of its \
decision on friday  clearing the way for it to conclude a 3 trillion

Tags: sumitomo mitsui financial, ufj holdings, mitsubishi tokyo, japanese banking

Article:france starts digital terrestrial france has become the last big european country to \
launch a digital terrestrial tv (dtt) service.  initially  more than a third of the \
population will be able to receive 14 free-to-air channels. despite the long wait for a \
french dtt roll-out  the new platform s bac

Tags: france, digital terrestrial

Article: apple laptop is  greatest gadget  the apple powerbook 100 has been chosen as the greatest \
gadget of all time  by us magazine mobile pc.  the 1991 laptop was chosen because it was \
one of the first  lightweight  portable computers and helped define the layout of all future \
notebook pcs. the magazine h

Tags: apple, apple powerbook 100, laptop


Article:{article}

Tags:"""


  response = co.chat(
    model='command-r',
    message=prompt,
    preamble="")

  return response.text
```

<img alt="Complete all steps" src="https://github.com/cohere-ai/cohere-developer-experience/raw/main/notebooks/images/article-recommender/article-rec-5.png" />

Let's now put everything together for our article recommender system.

First, we select the target article and compute the similarity scores against the candidate articles.

```python PYTHON
print(f'Choose one article ID between {INP_START} and {INP_END-1} below...')
```

```
Choose one article ID between 0 and 99 below...
```

```python PYTHON
READING_IDX = 70

reading = embeds[READING_IDX]

similarity = get_similarity(reading,embeds)
```

Next, we filter the articles via classification. Finally, we extract the keywords from each article and show the recommendations.

```python PYTHON
SHOW_TOP = 5

df_inputs = df_inputs.copy()
df_inputs['Text'] = df_inputs['Text'].apply(shorten_text)

def get_recommendations(reading_idx,similarity,show_top):

  # Show the current article
  print('------  You are reading...  ------')
  print(f'[ID {READING_IDX}] Article:',df_inputs['Text'][reading_idx][:MAX_CHARS]+'...\n')

  # Show the recommended articles
  print('------  You might also like...  ------')

  # Classify the target article
  target_class = classify_text([df_inputs['Text'][reading_idx]],examples)
  print(target_class)

  count = 0
  for idx,score in similarity:

    # Classify each candidate article
    candidate_class = classify_text([df_inputs['Text'][idx]],examples)

    # Show recommendations
    if target_class == candidate_class and idx != reading_idx:
      selection = df_inputs['Text'][idx][:MAX_CHARS]
      print(f'[ID {idx}] Article:',selection+'...')

      # Extract and show tags
      tags = extract_tags(selection)
      if tags:
          print(f'Tags: {tags.strip()}\n')
      else:
          print(f'Tags: none\n')

      # Increment the article count
      count += 1

      # Stop once articles reach the SHOW_TOP number
      if count == show_top:
        break
```

```python PYTHON
get_recommendations(READING_IDX,similarity,SHOW_TOP)
```

```
------  You are reading...  ------
[ID 70] Article: aragones angered by racism fine spain coach luis aragones is furious after being fined by the spanish football federation for his comments about thierry henry.  the 66-year-old criticised his 3000 euros (Â£2 060) punishment even though it was far below the maximum penalty.  i am not guilty  nor do i ...

------  You might also like...  ------
[ID 23] Article: ferguson urges henry punishment sir alex ferguson has called on the football association to punish arsenal s thierry henry for an incident involving gabriel heinze.  ferguson believes henry deliberately caught heinze on the head with his knee during united s controversial win. the united boss said i...
Tags: football, sir alex ferguson, thierry henry, arsenal, manchester united

[ID 51] Article: mourinho defiant on chelsea form chelsea boss jose mourinho has insisted that sir alex ferguson and arsene wenger would swap places with him.  mourinho s side were knocked out of the fa cup by newcastle last sunday before seeing barcelona secure a 2-1 champions league first-leg lead in the nou camp....
Tags: chelsea, jose mourinho, sir alex ferguson, arsene wenger, fa cup, newcastle, barcelona, champions league

[ID 41] Article: mcleish ready for criticism rangers manager alex mcleish accepts he is going to be criticised after their disastrous uefa cup exit at the hands of auxerre at ibrox on wednesday.  mcleish told bbc radio five live:  we were in pole position to get through to the next stage but we blew it  we absolutel...
Tags: rangers, alex mcleish, auxerre, uefa cup, ibrox

[ID 42] Article: premier league planning cole date the premier league is attempting to find a mutually convenient date to investigate allegations chelsea made an illegal approach for ashley cole.  both chelsea and arsenal will be asked to give evidence to a premier league commission  but no deadline has been put on ...
Tags: premier league, chelsea, arsenal, ashley cole

[ID 14] Article: ireland 21-19 argentina an injury-time dropped goal by ronan o gara stole victory for ireland from underneath the noses of argentina at lansdowne road on saturday.  o gara kicked all of ireland s points  with two dropped goals and five penalties  to give the home side a 100% record in their autumn i...
Tags: rugby, ireland, argentina, ronan o gara
```

Keeping to the Section 1.3 example, here we see how the classification and extraction steps have improved our recommendation outcome.

First, now the article with ID 73 (non sport) doesn't get recommended anymore. And now we have the tags related to each article being generated.

Let's try a couple of other articles in business and tech and see the output...

Business article (returning recommendations around German economy and economic growth/slump):

```python PYTHON

READING_IDX = 1

reading = embeds[READING_IDX]

similarity = get_similarity(reading,embeds)

get_recommendations(READING_IDX,similarity,SHOW_TOP)
```

```
------  You are reading...  ------
[ID 1] Article: german business confidence slides german business confidence fell in february knocking hopes of a speedy recovery in europe s largest economy.  munich-based research institute ifo said that its confidence index fell to 95.5 in february from 97.5 in january  its first decline in three months. the stu...

------  You might also like...  ------
[ID 56] Article: borussia dortmund near bust german football club and former european champion borussia dortmund has warned it will go bankrupt if rescue talks with creditors fail.  the company s shares tumbled after it said it has  entered a life-threatening profitability and financial situation . borussia dortmund...
Tags: borussia dortmund, german football, bankruptcy

[ID 2] Article: bbc poll indicates economic gloom citizens in a majority of nations surveyed in a bbc world service poll believe the world economy is worsening.  most respondents also said their national economy was getting worse. but when asked about their own family s financial outlook  a majority in 14 countries...
Tags: bbc, economy, financial outlook

[ID 8] Article: car giant hit by mercedes slump a slump in profitability at luxury car maker mercedes has prompted a big drop in profits at parent daimlerchrysler.  the german-us carmaker saw fourth quarter operating profits fall to 785m euros ($1bn) from 2.4bn euros in 2003. mercedes-benz s woes - its profits slid...
Tags: daimlerchrysler, mercedes, luxury car, profitability

[ID 32] Article: china continues rapid growth china s economy has expanded by a breakneck 9.5% during 2004  faster than predicted and well above 2003 s 9.1%.  the news may mean more limits on investment and lending as beijing tries to take the economy off the boil. china has sucked in raw materials and energy to fee...
Tags: china, economy, beijing

[ID 96] Article: bmw to recall faulty diesel cars bmw is to recall all cars equipped with a faulty diesel fuel-injection pump supplied by parts maker robert bosch.  the faulty part does not represent a safety risk and the recall only affects pumps made in december and january. bmw said that it was too early to say h...
Tags: bmw, diesel cars, robert bosch, fuel injection pump
```

Tech article (returning recommendations around consumer devices):

```python PYTHON

READING_IDX = 71

reading = embeds[READING_IDX]

similarity = get_similarity(reading,embeds)

get_recommendations(READING_IDX,similarity,SHOW_TOP)
```

```txt title="Output"
------  You are reading...  ------
[ID 71] Article: camera phones are  must-haves  four times more mobiles with cameras in them will be sold in europe by the end of 2004 than last year  says a report from analysts gartner.  globally  the number sold will reach 159 million  an increase of 104%. the report predicts that nearly 70% of all mobile phones ...

------  You might also like...  ------
[ID 3] Article: lifestyle  governs mobile choice  faster  better or funkier hardware alone is not going to help phone firms sell more handsets  research suggests.  instead  phone firms keen to get more out of their customers should not just be pushing the technology for its own sake. consumers are far more interest...
Tags: mobile, lifestyle, phone firms, handsets

[ID 69] Article: gates opens biggest gadget fair bill gates has opened the consumer electronics show (ces) in las vegas  saying that gadgets are working together more to help people manage multimedia content around the home and on the move.  mr gates made no announcement about the next generation xbox games console ...
Tags: bill gates, consumer electronics show, gadgets, xbox

[ID 46] Article: china  ripe  for media explosion asia is set to drive global media growth to 2008 and beyond  with china and india filling the two top spots  analysts have predicted.  japan  south korea and singapore will also be strong players  but china s demographics give it the edge  a media conference in londo...
Tags: china, india, japan, south korea, singapore, global media growth

[ID 19] Article: moving mobile improves golf swing a mobile phone that recognises and responds to movements has been launched in japan.  the motion-sensitive phone - officially titled the v603sh - was developed by sharp and launched by vodafone s japanese division. devised mainly for mobile gaming  users can also ac...
Tags: mobile phone, japan, sharp, vodafone, golf swing

[ID 63] Article: what high-definition will do to dvds first it was the humble home video  then it was the dvd  and now hollywood is preparing for the next revolution in home entertainment - high-definition.  high-definition gives incredible  3d-like pictures and surround sound. the dvd disks and the gear to play the...
Tags: high-definition, dvd, hollywood, home entertainment
```

In conclusion, this demonstrates an example of how we can stack multiple NLP endpoints together to get an output much closer to our desired outcome.

In practice, hosting and maintaining multiple models can turn quickly into a complex activity. But by leveraging Cohere endpoints, this task is reduced to a simple API call.

```
```



---

**Navigation:** [â† Previous](./13-updates-a-fine-tuned-model.md) | [Index](./index.md) | [Next â†’](./15-multi-step-tool-use-with-cohere.md)
