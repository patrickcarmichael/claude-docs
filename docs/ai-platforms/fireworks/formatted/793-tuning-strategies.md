---
title: "Fireworks Documentation"
description: "Formatted documentation for Fireworks"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Tuning Strategies

Best practices for adjusting parameters to achieve your training goals.

<AccordionGroup>
  <Accordion title="Start with Defaults">
    The default parameters are carefully tuned to work well for most RFT tasks. Don't change them unless you have a clear hypothesis based on your training metrics.

    Run at least one baseline experiment with defaults before making any adjustments. This gives you:

    * A performance benchmark to compare against
    * Understanding of whether parameter tuning is actually needed
    * Evidence about which metrics need improvement

    Many successful RFT jobs use all default parameters.
  </Accordion>

  <Accordion title="One Change at a Time">
    When you do adjust parameters, change only one at a time and measure the impact on your reward curves and evaluation metrics.

    **Good workflow:**

    1. Run baseline with defaults
    2. Identify specific issue (e.g., reward crashes, slow convergence)
    3. Change ONE parameter that should address that issue
    4. Compare results
    5. Repeat

    **Avoid:** Changing multiple parameters simultaneouslyâ€”you won't know which change caused the improvement or regression.
  </Accordion>

  <Accordion title="Track Everything">
    Use Weights & Biases integration to:

    * Compare training curves across experiments
    * Track reward progression over time
    * Monitor hardware utilization (memory, GPU usage)
    * Log all hyperparameters automatically

    This makes it easy to identify which parameter changes actually helped and which hurt performance.
  </Accordion>

  <Accordion title="Common Patterns">
    Quick reference for goal-directed parameter tuning:

    * **Faster convergence** â†’ â†‘ epochs (add 1-2), tune learning rate (stay \<2Ã— default)
    * **Better quality** â†’ â†‘ temperature (1.0-1.2), â†‘ rollouts (6-8), â†‘ max tokens
    * **Safer/less toxic** â†’ â†“ temperature (0.3-0.5), â†“ top-p (0.5), â†“ top-k
    * **More creative** â†’ â†‘ temperature (1.0-1.2), top-p = 0.9
    * **Lower cost** â†’ â†“ rollouts, â†“ max tokens, â†“ batch size
    * **Higher capacity** â†’ â†‘ LoRA rank (16-32), but monitor memory usage
    * **Prevent overfitting** â†’ Keep epochs = 1, consider lower LoRA rank
  </Accordion>
</AccordionGroup>

---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
