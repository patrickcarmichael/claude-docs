---
title: "Fireworks Documentation"
description: "Formatted documentation for Fireworks"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## What is a Reward Function?

A reward function is a mechanism for evaluating the quality of model outputs in reinforcement learning from verifiable reward (RLVR) workflows. Reward functions help:

* Evaluate model responses based on specific criteria.
* Provide numerical scores that can be used to optimize models.
* Offer explanations for why specific scores were assigned.

---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
