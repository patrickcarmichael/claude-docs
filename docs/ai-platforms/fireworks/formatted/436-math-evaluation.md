---
title: "Fireworks Documentation"
description: "Formatted documentation for Fireworks"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Math Evaluation

This guide explains how to evaluate mathematical answers in LLM responses, primarily focusing on the `math_reward` function.

**For a complete, runnable example of math evaluation using the GSM8K dataset, including Hydra configuration for `reward-kit run`, please refer to the [Math Example README](https://github.com/fw-ai-external/reward-kit/blob/main/examples/math_example/README.md) located in the `examples/math_example/` directory.**

The content below details the capabilities and programmatic usage of the underlying `math_reward` function, which is utilized within the `examples/math_example`.

---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
