---
title: "Fireworks Documentation"
description: "Formatted documentation for Fireworks"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Introduction

In this demo, we will demonstrate how thoughtful rewardâ€‘function design can steer a language model toward producing clear, 50â€‘token summaries that balance brevity with relevance. Using Fireworksâ€™ reinforcementâ€‘fineâ€‘tuning workflow, youâ€™ll see how adjusting a few wellâ€‘chosen signals can transform raw model outputs into reliable digests suitable for news briefs, chat recaps, and study notesâ€”revealing, along the way, why defeating reward hacking is central to building trustworthy summarizers.

### Goals

Every summarizer will look different. Letâ€™s set up some goals:

* Use `llama-v3p1-8b-instruct` to balance speed and model intelligence
* Summaries should be under 50 tokens
* Summaries should capture relevant information within a much larger text

### Why Reinforcement Fine-Tune?

Reinforcementâ€¯Fineâ€‘Tuning augments standard supervised training by adding a reward signal that scores each model output after it is generated. Instead of optimizing only for nextâ€‘token likelihood, the model learns from these scoresâ€”gradually preferring strategies that maximize the reward and discarding those that do not.

Traditional supervised fineâ€‘tuning simply teaches a model to imitate example summaries, but it never checks whether the *finished* output actually satisfies our broader goalsâ€”like striking the right balance between brevity and substance. Reinforcement â€¯Fineâ€‘Tuning adds a feedback step after each summary is generated, letting us reward outputs that hit that balance and discourage ones that donâ€™t. Because we can adjust this feedback on the fly, RFT gives us a practical steering mechanism: tweak the reward, observe how the model adapts, and quickly converge on summaries that are both concise and informative. For this sort of summarization task, that endâ€‘toâ€‘end feedback loop is essentialâ€”imitation alone canâ€™t capture the nuanced tradeâ€‘offs we care about.

For more information on RFT on the Fireworks platform and when to use it, take a look at our examples on Knowledge Distillation

---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
