---
title: "Together AI Documentation"
description: "Formatted documentation for Together AI"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Digging deeper

Weâ€™ve built out the main flow of our app using just two endpoints: one that blocks on an API request to Exa AI, and one that returns a stream using Togetherâ€™s Node SDK.

React and Next.js were a great fit for this app, giving us all the tools and flexibility we needed to make a complete full-stack web app with secure server-side logic and reactive client-side updates.

[TurboSeek](https://www.turboseek.io/) is fully open-source and has even more features like suggesting similar questions, so if you want to keep working on the code from this tutorial, be sure to check it out on GitHub:

[https://github.com/Nutlope/turboseek/](https://github.com/Nutlope/turboseek/)

And if youâ€™re ready to add streaming LLM features like the chat completions we saw above to your own apps, [sign up for Together AI today](https://www.together.ai/), get \$5 for free to start out, and make your first query in minutes!

***


---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
