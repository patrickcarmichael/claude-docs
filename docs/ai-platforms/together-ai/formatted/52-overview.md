---
title: "Together AI Documentation"
description: "Formatted documentation for Together AI"
source: "llms-full.txt"
last_updated: "2025-11-08"
---

## Overview

The Batch API enables you to process large volumes of requests asynchronously at up to 50% lower cost compared to real-time API calls. It's perfect for workloads that don't need immediate responses such as:

* Running evaluations and data analysis
* Classifying large datasets
* Offline summarization
* Synthetic data generation
* Content generation for marketing
* Dataset processing and transformations

Compared to using standard endpoints directly, Batch API offers:

* **Better cost efficiency**: 50% cost discount compared to synchronous APIs
* **Higher rate limits**: Substantially more headroom with separate rate limit pools
* **Large-scale support**: Process thousands of requests per batch
* **Flexible completion**: Best-effort completion within 24 hours with progress tracking

---

**ðŸ“š [Back to Index](./index.md)** | **ðŸ“„ [Full Version](./documentation.md)** | **ðŸ”— [Original](../llms-full.txt)**
