---
title: "Llamaindex: Use Cases by Provider Category"
description: "Use Cases by Provider Category section of Llamaindex documentation"
source: "https://llamaindex.com"
last_updated: "2025-11-08"
---

## Use Cases by Provider Category


### For Production Reliability

- **Primary**: OpenAI, Azure OpenAI, AWS Bedrock
- **Fallback**: Anthropic Claude, Cohere
- **Benefit**: Established SLAs, enterprise support

### For Cost Optimization

- **Primary**: Ollama (free, local), Mistral, Together AI
- **Secondary**: Groq, Fireworks
- **Benefit**: Significant cost reduction at scale

### For Privacy & Control

- **Primary**: Ollama, LlamaCPP, LM Studio
- **Secondary**: Self-hosted vLLM
- **Benefit**: Complete data sovereignty, no external calls

### For Cutting-Edge Capabilities

- **Primary**: OpenAI GPT-4, Claude 3 Opus
- **Secondary**: Google Gemini, Mistral Large
- **Benefit**: Latest research, best performance

### For Multi-Modal Applications

- **Primary**: OpenAI (Vision), Gemini
- **Secondary**: Claude 3 Vision
- **Benefit**: Image understanding, document analysis

### For Real-Time Applications

- **Primary**: Groq, Fireworks
- **Secondary**: Together AI
- **Benefit**: Sub-second latencies

---

## Navigation

- [üìë Back to Index](./index.md)
- [üìÑ Full Documentation](./documentation.md)
- [üìù Original Source](../llms-full.txt)

**Previous:** [‚Üê Configuration and Usage](./03-configuration-and-usage.md)

**Next:** [Integration Examples ‚Üí](./05-integration-examples.md)
