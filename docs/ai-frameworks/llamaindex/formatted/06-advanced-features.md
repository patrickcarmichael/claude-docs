---
title: "Llamaindex: Advanced Features"
description: "Advanced Features section of Llamaindex documentation"
source: "https://llamaindex.com"
last_updated: "2025-11-08"
---

## Advanced Features


### Streaming Support

- Real-time token streaming for interactive applications
- Supported by: All major providers
- Use Cases: Chat interfaces, live response generation

### Function Calling / Tool Use

- Structured output for agent workflows
- Supported by: OpenAI, Anthropic, Gemini, Mistral
- Use Cases: Agent task execution, structured extraction

### Vision/Multi-Modal

- Image analysis and understanding
- Supported by: OpenAI, Claude 3, Gemini
- Use Cases: Document analysis, visual QA

### Long Context Windows

- Extended input length support
- Leaders: Claude 3 (200K tokens), GPT-4 Turbo (128K), Gemini (1M)
- Use Cases: Document processing, long conversation history

### Token Counting

- Accurate token estimation before API calls
- Supported by: All providers with native support
- Use Cases: Cost prediction, budget management

### Caching and Optimization

- Reduce API costs through intelligent caching
- Supported by: Anthropic, OpenAI
- Use Cases: Frequent queries, cost optimization

---

## Navigation

- [üìë Back to Index](./index.md)
- [üìÑ Full Documentation](./documentation.md)
- [üìù Original Source](../llms-full.txt)

**Previous:** [‚Üê Integration Examples](./05-integration-examples.md)

**Next:** [Selection Criteria ‚Üí](./07-selection-criteria.md)
