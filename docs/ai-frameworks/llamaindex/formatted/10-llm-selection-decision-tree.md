---
title: "Llamaindex: LLM Selection Decision Tree"
description: "LLM Selection Decision Tree section of Llamaindex documentation"
source: "https://llamaindex.com"
last_updated: "2025-11-08"
---

## LLM Selection Decision Tree


```
1. Need latest capabilities?
   â†’ Yes: OpenAI GPT-4, Claude 3 Opus, Gemini
   â†’ No: Proceed to 2

2. Have strict privacy requirements?
   â†’ Yes: Ollama, LlamaCPP, Self-hosted vLLM
   â†’ No: Proceed to 3

3. Cost is critical?
   â†’ Yes: Mistral, Together AI, Groq
   â†’ No: Proceed to 4

4. Need real-time low latency?
   â†’ Yes: Groq, Fireworks
   â†’ No: OpenAI, Claude, Gemini acceptable

5. Require vision capabilities?
   â†’ Yes: OpenAI, Claude 3, Gemini
   â†’ No: Any provider works

6. Enterprise requirements?
   â†’ Yes: Azure OpenAI, AWS Bedrock, Anthropic Enterprise
   â†’ No: Any provider acceptable
```

---

## Navigation

- [ğŸ“‘ Back to Index](./index.md)
- [ğŸ“„ Full Documentation](./documentation.md)
- [ğŸ“ Original Source](../llms-full.txt)

**Previous:** [â† Performance Considerations](./09-performance-considerations.md)

**Next:** [Resources â†’](./11-resources.md)
