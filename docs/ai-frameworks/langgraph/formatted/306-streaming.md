---
title: "Langgraph: Streaming"
description: "Streaming section of Langgraph documentation"
source: "https://langgraph.com"
last_updated: "2025-11-08"
---

# Streaming


LangGraph implements a streaming system to surface real-time updates, allowing for responsive and transparent user experiences.

LangGraphâ€™s streaming system lets you surface live feedback from graph runs to your app.  
There are three main categories of data you can stream:

1. **Workflow progress** â€” get state updates after each graph node is executed.
2. **LLM tokens** â€” stream language model tokens as theyâ€™re generated.
3. **Custom updates** â€” emit user-defined signals (e.g., â€œFetched 10/100 recordsâ€).

---

## Navigation

- [ğŸ“‘ Back to Index](./index.md)
- [ğŸ“„ Full Documentation](./documentation.md)
- [ğŸ“ Original Source](../llms-full.txt)

**Previous:** [â† Self-Hosted Data Plane](./305-self-hosted-data-plane.md)

**Next:** [Whatâ€™s possible with LangGraph streaming â†’](./307-whats-possible-with-langgraph-streaming.md)
