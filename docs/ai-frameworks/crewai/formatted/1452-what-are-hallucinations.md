---
title: "Crewai: What are Hallucinations?"
description: "What are Hallucinations? section of Crewai documentation"
source: "https://docs.crewai.com/en/concepts/agents"
last_updated: "2025-11-08"
---

## What are Hallucinations?


AI hallucinations occur when language models generate content that appears plausible but is factually incorrect or not supported by the provided context. The Hallucination Guardrail helps prevent these issues by:

* Comparing outputs against reference context
* Evaluating faithfulness to source material
* Providing detailed feedback on problematic content
* Supporting custom thresholds for validation strictness

---

## Navigation

- [ğŸ“‘ Back to Index](./index.md)
- [ğŸ“„ Full Documentation](./documentation.md)
- [ğŸ“ Original Source](../llms-full.txt)

**Previous:** [â† Overview](./1451-overview.md)

**Next:** [Basic Usage â†’](./1453-basic-usage.md)
